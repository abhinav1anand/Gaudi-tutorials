{
    "GlobalRank": null,
    "LocalRank": 0,
    "Mode": "Scale",
    "Nodes": {
        "transformer.h.0.attn.c_attn": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.0.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.0.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.0.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.0.mlp.c_proj": {
            "inputs": [
                16.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.1.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.1.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.1.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.1.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.1.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.2.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.2.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.2.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.2.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.2.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.3.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.3.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.3.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.3.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.3.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.4.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.4.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.4.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.4.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.4.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.5.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.5.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.5.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.5.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.5.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.6.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.6.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.6.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.6.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.6.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.7.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.7.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.7.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.7.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.7.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.8.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.8.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.8.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.8.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.8.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.9.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.9.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.9.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.9.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.9.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.10.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.10.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.10.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.10.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.10.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.11.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.11.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.11.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.11.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.11.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.12.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.12.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.12.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.12.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.12.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.13.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.13.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.13.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.13.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.13.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.14.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.14.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.14.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.14.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.14.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.15.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.15.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.15.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.15.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.15.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.16.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.16.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.16.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.16.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.16.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.17.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.17.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.17.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.17.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.17.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.18.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.18.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.18.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.18.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.18.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.19.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.19.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.19.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.19.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.19.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.20.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.20.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.20.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.20.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.20.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.21.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.21.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.21.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.21.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.21.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.22.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.22.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.22.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.22.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.22.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.23.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.23.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.23.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.23.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.23.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.24.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.24.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.24.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.24.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.24.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.25.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.25.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.25.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.25.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.25.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.26.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.26.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.26.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.26.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.26.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.27.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.27.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.27.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.27.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.27.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.28.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.28.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.28.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.28.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.28.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.29.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.29.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.29.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.29.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.29.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.30.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.30.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.30.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.30.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.30.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.31.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.31.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.31.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.31.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.31.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.32.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.32.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.32.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.32.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.32.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.33.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.33.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.33.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.33.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.33.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.34.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.34.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.34.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.34.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.34.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.35.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.35.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.35.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.35.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.35.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.36.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.36.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.36.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.36.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.36.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.37.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.37.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.37.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.37.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.37.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.38.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.38.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.38.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.38.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.38.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.39.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.39.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.39.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.39.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.39.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.40.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.40.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.40.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.40.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.40.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.41.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.41.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.41.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.41.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.41.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.42.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.42.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.42.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.42.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.42.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.43.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.43.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.43.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.43.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.43.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.44.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.44.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.44.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.44.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.44.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.45.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.45.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.45.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.45.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.45.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.46.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.46.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.46.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                0.0625
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.46.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.46.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.47.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.47.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.47.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.47.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.47.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.48.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.48.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.48.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                0.0625,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.48.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.48.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.49.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.49.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.49.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.49.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.49.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.50.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.50.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.50.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.50.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.50.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.51.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.51.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.51.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.51.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.51.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.52.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.52.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.52.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.52.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.52.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.52.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.52.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.52.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.52.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.52.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.52.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.53.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.53.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.53.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.53.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.53.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.53.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.53.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.53.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.53.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.53.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.53.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.54.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.54.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.54.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.54.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.54.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.54.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.54.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.54.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.54.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.54.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.54.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.55.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.55.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.55.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.55.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.55.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.55.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.55.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.55.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.55.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.55.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.55.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.56.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.56.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.56.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.56.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.56.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.56.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.56.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.56.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.56.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.56.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.56.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.57.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.57.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.57.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.57.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.57.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.57.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.57.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.57.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.57.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.57.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.57.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.58.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.58.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.58.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.58.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.58.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.58.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.58.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.58.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.58.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.58.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.58.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.59.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.59.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.59.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.59.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.59.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.59.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.59.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.59.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.59.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.59.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.59.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.60.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.60.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.60.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.60.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.60.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.60.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.60.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.60.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.60.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.60.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.60.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.61.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.61.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.61.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.61.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.61.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.61.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.61.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.61.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.61.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.61.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.61.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.62.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.62.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.62.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.62.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.62.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.62.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.62.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.62.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.62.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.62.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.62.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.63.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.63.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.63.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.63.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.63.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.63.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.63.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.63.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.63.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.63.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.63.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.64.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.64.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.64.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.64.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.64.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.64.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.64.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.64.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.64.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.64.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.64.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.65.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.65.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.65.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.65.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.65.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.65.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.65.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.65.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.65.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.65.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.65.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.66.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.66.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.66.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.66.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.66.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.66.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.66.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.66.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.66.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.66.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.66.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.67.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.67.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.67.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.67.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.67.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.67.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.67.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.67.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.67.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.67.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.67.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.68.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.68.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.68.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.68.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.68.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.68.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.68.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.68.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.68.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.68.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.68.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.69.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.69.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.69.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.69.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.69.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.69.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.69.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.69.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.69.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.69.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.69.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.70.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.70.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.70.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.70.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.70.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.70.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.70.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.70.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.70.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.70.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.70.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.71.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.71.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.71.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.71.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.71.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.71.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.71.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.71.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.71.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.71.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.71.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.72.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.72.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.72.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.72.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.72.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.72.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.72.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.72.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.72.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.72.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.72.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.73.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.73.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.73.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.73.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.73.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.73.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.73.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.73.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.73.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.73.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.73.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.74.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.74.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.74.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.74.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.74.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.74.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.74.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.74.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.74.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.74.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.74.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.75.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.75.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.75.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.75.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.75.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.75.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.75.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.75.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.75.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.75.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.75.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.76.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.76.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.76.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.76.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.76.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.76.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.76.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.76.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.76.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.76.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.76.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.77.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.77.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.77.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.77.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.77.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.77.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.77.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.77.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.77.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.77.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.77.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.78.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.78.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.78.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.78.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.78.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.78.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.78.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.78.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.78.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.78.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.78.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.79.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.79.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.79.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.79.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.79.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.79.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.79.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.79.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.79.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.79.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.79.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.80.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.80.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.80.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.80.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.80.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.80.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.80.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.80.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.80.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.80.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.80.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.81.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.81.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.81.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.81.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.81.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.81.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.81.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.81.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.81.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.81.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.81.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.82.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.82.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.82.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.82.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.82.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.82.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.82.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.82.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.82.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.82.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.82.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.83.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.83.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.83.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.83.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.83.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.83.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.83.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.83.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.83.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.83.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.83.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.84.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.84.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.84.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.84.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.84.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.84.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.84.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.84.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.84.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.84.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.84.mlp.c_proj": {
            "inputs": [
                16.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.85.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.85.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.85.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.85.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.85.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.85.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.85.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.85.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.85.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.85.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.85.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.86.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.86.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.86.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.86.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.86.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.86.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.86.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.86.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.86.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.86.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.86.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.87.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.87.attn.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.87.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.87.attn.attn.impl.matmul_av": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.87.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.0625,
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.87.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.0625,
                1.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.87.attn.attn.impl.k_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.87.attn.attn.impl.v_cache": {
            "inputs": [
                1.0
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.87.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                1.0,
                1.0,
                1.0,
                0.0625
            ],
            "outputs": [
                1.0
            ],
            "params": {}
        },
        "transformer.h.87.mlp.c_fc": {
            "inputs": [
                16.0
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0625
            }
        },
        "transformer.h.87.mlp.c_proj": {
            "inputs": [
                16.0
            ],
            "outputs": [
                16.0
            ],
            "params": {
                "weight": 0.0625
            }
        }
    }
}