{"GlobalRank": null, "LocalRank": 0, "Mode": "DynamicRange", "Nodes": {"model.layers.0.self_attn.qkv_proj": {"inputs": [[[692.0]]], "params": {"weight": [[0.2734375]]}}, "model.layers.0.self_attn.o_proj": {"inputs": [[[35.0]]], "outputs": [[[34.75]], [[9.865364031216172e+34]]], "params": {"weight": [[0.546875]]}}, "model.layers.0.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.21875]], [[200.0]]]}, "model.layers.0.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[62.25]]]}, "model.layers.0.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[302.0]]]}, "model.layers.0.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[54.25]]]}, "model.layers.0.self_attn.attn.impl.k_cache": {"inputs": [[[200.0]]]}, "model.layers.0.self_attn.attn.impl.v_cache": {"inputs": [[[62.25]]]}, "model.layers.0.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[156.0]], [[200.0]], [[62.25]]], "outputs": [[[35.0]], [[1.0]]]}, "model.layers.0.mlp.gate_up_proj": {"inputs": [[[144.0]]], "params": {"weight": [[0.82421875]]}}, "model.layers.0.mlp.down_proj": {"inputs": [[[192.0]]], "outputs": [[[113.5]], [[4.8028745941447156e+35]]], "params": {"weight": [[0.9453125]]}}, "model.layers.1.self_attn.qkv_proj": {"inputs": [[[164.0]]], "params": {"weight": [[0.466796875]]}}, "model.layers.1.self_attn.o_proj": {"inputs": [[[10.25]]], "outputs": [[[9.5625]], [[9.865364031216172e+34]]], "params": {"weight": [[0.42578125]]}}, "model.layers.1.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.33203125]], [[118.0]]]}, "model.layers.1.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.125]]]}, "model.layers.1.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[163.0]]]}, "model.layers.1.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[53.25]]]}, "model.layers.1.self_attn.attn.impl.k_cache": {"inputs": [[[118.0]]]}, "model.layers.1.self_attn.attn.impl.v_cache": {"inputs": [[[14.125]]]}, "model.layers.1.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[41.25]], [[118.0]], [[13.625]]], "outputs": [[[10.25]], [[1.0]]]}, "model.layers.1.mlp.gate_up_proj": {"inputs": [[[94.5]]], "params": {"weight": [[0.423828125]]}}, "model.layers.1.mlp.down_proj": {"inputs": [[[132.0]]], "outputs": [[[50.5]], [[1.2007186485361789e+35]]], "params": {"weight": [[0.392578125]]}}, "model.layers.2.self_attn.qkv_proj": {"inputs": [[[117.5]]], "params": {"weight": [[0.408203125]]}}, "model.layers.2.self_attn.o_proj": {"inputs": [[[9.625]]], "outputs": [[[13.1875]], [[1.1617764220971677e+35]]], "params": {"weight": [[0.478515625]]}}, "model.layers.2.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.236328125]], [[84.0]]]}, "model.layers.2.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[10.9375]]]}, "model.layers.2.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[174.0]]]}, "model.layers.2.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[54.5]]]}, "model.layers.2.self_attn.attn.impl.k_cache": {"inputs": [[[84.0]]]}, "model.layers.2.self_attn.attn.impl.v_cache": {"inputs": [[[10.9375]]]}, "model.layers.2.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[30.625]], [[83.0]], [[10.9375]]], "outputs": [[[9.625]], [[1.0]]]}, "model.layers.2.mlp.gate_up_proj": {"inputs": [[[54.25]]], "params": {"weight": [[0.55078125]]}}, "model.layers.2.mlp.down_proj": {"inputs": [[[2688.0]]], "outputs": [[[1992.0]], [[1.3564875542922237e+35]]], "params": {"weight": [[0.66796875]]}}, "model.layers.3.self_attn.qkv_proj": {"inputs": [[[110.5]]], "params": {"weight": [[0.4375]]}}, "model.layers.3.self_attn.o_proj": {"inputs": [[[9.5]]], "outputs": [[[8.5]], [[4.195375861696141e+36]]], "params": {"weight": [[0.32421875]]}}, "model.layers.3.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.384765625]], [[79.0]]]}, "model.layers.3.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[11.4375]]]}, "model.layers.3.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[280.0]]]}, "model.layers.3.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[61.25]]]}, "model.layers.3.self_attn.attn.impl.k_cache": {"inputs": [[[79.0]]]}, "model.layers.3.self_attn.attn.impl.v_cache": {"inputs": [[[11.4375]]]}, "model.layers.3.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[49.0]], [[78.5]], [[11.1875]]], "outputs": [[[9.5]], [[1.0]]]}, "model.layers.3.mlp.gate_up_proj": {"inputs": [[[22.125]]], "params": {"weight": [[0.251953125]]}}, "model.layers.3.mlp.down_proj": {"inputs": [[[76.5]]], "outputs": [[[89.0]], [[6.3930155070710065e+34]]], "params": {"weight": [[0.5390625]]}}, "model.layers.4.self_attn.qkv_proj": {"inputs": [[[145.0]]], "params": {"weight": [[0.2021484375]]}}, "model.layers.4.self_attn.o_proj": {"inputs": [[[9.75]]], "outputs": [[[10.1875]], [[1.0644208559996397e+35]]], "params": {"weight": [[0.359375]]}}, "model.layers.4.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.419921875]], [[76.5]]]}, "model.layers.4.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.25]]]}, "model.layers.4.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[520.0]]]}, "model.layers.4.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[105.5]]]}, "model.layers.4.self_attn.attn.impl.k_cache": {"inputs": [[[76.5]]]}, "model.layers.4.self_attn.attn.impl.v_cache": {"inputs": [[[14.25]]]}, "model.layers.4.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[54.0]], [[76.5]], [[14.25]]], "outputs": [[[9.75]], [[1.0]]]}, "model.layers.4.mlp.gate_up_proj": {"inputs": [[[28.75]]], "params": {"weight": [[0.384765625]]}}, "model.layers.4.mlp.down_proj": {"inputs": [[[2144.0]]], "outputs": [[[2496.0]], [[1.1838436837459407e+36]]], "params": {"weight": [[0.59765625]]}}, "model.layers.5.self_attn.qkv_proj": {"inputs": [[[185.0]]], "params": {"weight": [[0.59765625]]}}, "model.layers.5.self_attn.o_proj": {"inputs": [[[10.375]]], "outputs": [[[11.625]], [[4.195375861696141e+36]]], "params": {"weight": [[0.453125]]}}, "model.layers.5.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.43359375]], [[72.0]]]}, "model.layers.5.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.4375]]]}, "model.layers.5.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[528.0]]]}, "model.layers.5.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[109.0]]]}, "model.layers.5.self_attn.attn.impl.k_cache": {"inputs": [[[72.0]]]}, "model.layers.5.self_attn.attn.impl.v_cache": {"inputs": [[[15.4375]]]}, "model.layers.5.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[54.25]], [[72.0]], [[15.4375]]], "outputs": [[[10.3125]], [[1.0]]]}, "model.layers.5.mlp.gate_up_proj": {"inputs": [[[103.5]]], "params": {"weight": [[0.400390625]]}}, "model.layers.5.mlp.down_proj": {"inputs": [[[28032.0]]], "outputs": [[[22272.0]], [[2.3235528441943354e+35]]], "params": {"weight": [[0.76171875]]}}, "model.layers.6.self_attn.qkv_proj": {"inputs": [[[142.0]]], "params": {"weight": [[0.259765625]]}}, "model.layers.6.self_attn.o_proj": {"inputs": [[[9.5]]], "outputs": [[[17.625]], [[2.7389365928771216e+35]]], "params": {"weight": [[0.353515625]]}}, "model.layers.6.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.455078125]], [[77.0]]]}, "model.layers.6.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[25.875]]]}, "model.layers.6.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[49.5]]]}, "model.layers.6.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[22.625]]]}, "model.layers.6.self_attn.attn.impl.k_cache": {"inputs": [[[77.0]]]}, "model.layers.6.self_attn.attn.impl.v_cache": {"inputs": [[[25.875]]]}, "model.layers.6.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[58.25]], [[72.5]], [[24.0]]], "outputs": [[[9.5]], [[1.0]]]}, "model.layers.6.mlp.gate_up_proj": {"inputs": [[[52.75]]], "params": {"weight": [[0.314453125]]}}, "model.layers.6.mlp.down_proj": {"inputs": [[[49.25]]], "outputs": [[[28.75]], [[1.116343824584988e+36]]], "params": {"weight": [[0.44140625]]}}, "model.layers.7.self_attn.qkv_proj": {"inputs": [[[152.0]]], "params": {"weight": [[0.22265625]]}}, "model.layers.7.self_attn.o_proj": {"inputs": [[[9.75]]], "outputs": [[[14.4375]], [[1.3564875542922237e+35]]], "params": {"weight": [[0.48828125]]}}, "model.layers.7.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.453125]], [[70.5]]]}, "model.layers.7.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.0625]]]}, "model.layers.7.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[38.5]]]}, "model.layers.7.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[16.875]]]}, "model.layers.7.self_attn.attn.impl.k_cache": {"inputs": [[[70.5]]]}, "model.layers.7.self_attn.attn.impl.v_cache": {"inputs": [[[12.0625]]]}, "model.layers.7.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.25]], [[66.0]], [[11.9375]]], "outputs": [[[9.25]], [[1.0]]]}, "model.layers.7.mlp.gate_up_proj": {"inputs": [[[33.5]]], "params": {"weight": [[0.3125]]}}, "model.layers.7.mlp.down_proj": {"inputs": [[[60.25]]], "outputs": [[[20.75]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.5]]}}, "model.layers.8.self_attn.qkv_proj": {"inputs": [[[208.0]]], "params": {"weight": [[0.2041015625]]}}, "model.layers.8.self_attn.o_proj": {"inputs": [[[9.875]]], "outputs": [[[15.125]], [[7.962430332683566e+30]]], "params": {"weight": [[0.43359375]]}}, "model.layers.8.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.48828125]], [[77.5]]]}, "model.layers.8.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[16.0]]]}, "model.layers.8.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[43.25]]]}, "model.layers.8.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[18.375]]]}, "model.layers.8.self_attn.attn.impl.k_cache": {"inputs": [[[77.5]]]}, "model.layers.8.self_attn.attn.impl.v_cache": {"inputs": [[[16.0]]]}, "model.layers.8.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[65.5]], [[72.5]], [[14.4375]]], "outputs": [[[8.5625]], [[1.0]]]}, "model.layers.8.mlp.gate_up_proj": {"inputs": [[[29.0]]], "params": {"weight": [[0.28515625]]}}, "model.layers.8.mlp.down_proj": {"inputs": [[[42.5]]], "outputs": [[[17.875]], [[1.116343824584988e+36]]], "params": {"weight": [[0.58203125]]}}, "model.layers.9.self_attn.qkv_proj": {"inputs": [[[206.0]]], "params": {"weight": [[0.302734375]]}}, "model.layers.9.self_attn.o_proj": {"inputs": [[[10.3125]]], "outputs": [[[18.5]], [[1.129324566731325e+35]]], "params": {"weight": [[0.333984375]]}}, "model.layers.9.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.4921875]], [[81.5]]]}, "model.layers.9.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.25]]]}, "model.layers.9.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[24.875]]]}, "model.layers.9.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[16.5]]]}, "model.layers.9.self_attn.attn.impl.k_cache": {"inputs": [[[81.5]]]}, "model.layers.9.self_attn.attn.impl.v_cache": {"inputs": [[[12.25]]]}, "model.layers.9.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.0]], [[74.0]], [[12.25]]], "outputs": [[[9.25]], [[1.0]]]}, "model.layers.9.mlp.gate_up_proj": {"inputs": [[[26.0]]], "params": {"weight": [[0.3359375]]}}, "model.layers.9.mlp.down_proj": {"inputs": [[[41.5]]], "outputs": [[[18.0]], [[1.492785346828763e+35]]], "params": {"weight": [[0.5390625]]}}, "model.layers.10.self_attn.qkv_proj": {"inputs": [[[219.0]]], "params": {"weight": [[0.267578125]]}}, "model.layers.10.self_attn.o_proj": {"inputs": [[[11.5]]], "outputs": [[[17.75]], [[2.7389365928771216e+35]]], "params": {"weight": [[0.54296875]]}}, "model.layers.10.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.53515625]], [[81.0]]]}, "model.layers.10.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.875]]]}, "model.layers.10.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[44.0]]]}, "model.layers.10.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[20.625]]]}, "model.layers.10.self_attn.attn.impl.k_cache": {"inputs": [[[81.0]]]}, "model.layers.10.self_attn.attn.impl.v_cache": {"inputs": [[[12.875]]]}, "model.layers.10.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[69.5]], [[76.5]], [[12.75]]], "outputs": [[[11.5]], [[1.0]]]}, "model.layers.10.mlp.gate_up_proj": {"inputs": [[[25.875]]], "params": {"weight": [[0.341796875]]}}, "model.layers.10.mlp.down_proj": {"inputs": [[[36.75]]], "outputs": [[[22.5]], [[1.031969000633797e+35]]], "params": {"weight": [[0.57421875]]}}, "model.layers.11.self_attn.qkv_proj": {"inputs": [[[250.0]]], "params": {"weight": [[0.28125]]}}, "model.layers.11.self_attn.o_proj": {"inputs": [[[12.5625]]], "outputs": [[[21.375]], [[1.4798046046824259e+35]]], "params": {"weight": [[0.359375]]}}, "model.layers.11.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.51953125]], [[85.0]]]}, "model.layers.11.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.4375]]]}, "model.layers.11.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[38.5]]]}, "model.layers.11.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[20.625]]]}, "model.layers.11.self_attn.attn.impl.k_cache": {"inputs": [[[85.0]]]}, "model.layers.11.self_attn.attn.impl.v_cache": {"inputs": [[[15.4375]]]}, "model.layers.11.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[70.5]], [[79.0]], [[15.4375]]], "outputs": [[[11.3125]], [[1.0]]]}, "model.layers.11.mlp.gate_up_proj": {"inputs": [[[26.5]]], "params": {"weight": [[0.349609375]]}}, "model.layers.11.mlp.down_proj": {"inputs": [[[41.75]]], "outputs": [[[25.125]], [[1.1838436837459407e+36]]], "params": {"weight": [[0.443359375]]}}, "model.layers.12.self_attn.qkv_proj": {"inputs": [[[322.0]]], "params": {"weight": [[0.2734375]]}}, "model.layers.12.self_attn.o_proj": {"inputs": [[[12.0]]], "outputs": [[[21.25]], [[7.962430332683566e+30]]], "params": {"weight": [[0.431640625]]}}, "model.layers.12.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.478515625]], [[90.0]]]}, "model.layers.12.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[13.4375]]]}, "model.layers.12.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[42.0]]]}, "model.layers.12.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.75]]]}, "model.layers.12.self_attn.attn.impl.k_cache": {"inputs": [[[90.0]]]}, "model.layers.12.self_attn.attn.impl.v_cache": {"inputs": [[[13.4375]]]}, "model.layers.12.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.0]], [[75.0]], [[13.4375]]], "outputs": [[[10.9375]], [[1.0]]]}, "model.layers.12.mlp.gate_up_proj": {"inputs": [[[31.75]]], "params": {"weight": [[0.345703125]]}}, "model.layers.12.mlp.down_proj": {"inputs": [[[38.0]]], "outputs": [[[23.0]], [[2.7389365928771216e+35]]], "params": {"weight": [[0.482421875]]}}, "model.layers.13.self_attn.qkv_proj": {"inputs": [[[248.0]]], "params": {"weight": [[0.353515625]]}}, "model.layers.13.self_attn.o_proj": {"inputs": [[[10.9375]]], "outputs": [[[22.0]], [[4.195375861696141e+36]]], "params": {"weight": [[0.71875]]}}, "model.layers.13.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.51953125]], [[89.0]]]}, "model.layers.13.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.75]]]}, "model.layers.13.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[57.5]]]}, "model.layers.13.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[26.875]]]}, "model.layers.13.self_attn.attn.impl.k_cache": {"inputs": [[[89.0]]]}, "model.layers.13.self_attn.attn.impl.v_cache": {"inputs": [[[14.75]]]}, "model.layers.13.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[68.0]], [[78.5]], [[14.125]]], "outputs": [[[10.1875]], [[1.0]]]}, "model.layers.13.mlp.gate_up_proj": {"inputs": [[[27.125]]], "params": {"weight": [[0.27734375]]}}, "model.layers.13.mlp.down_proj": {"inputs": [[[39.75]]], "outputs": [[[28.5]], [[1.492785346828763e+35]]], "params": {"weight": [[0.56640625]]}}, "model.layers.14.self_attn.qkv_proj": {"inputs": [[[245.0]]], "params": {"weight": [[0.1708984375]]}}, "model.layers.14.self_attn.o_proj": {"inputs": [[[13.0625]]], "outputs": [[[35.25]], [[9.865364031216172e+34]]], "params": {"weight": [[0.70703125]]}}, "model.layers.14.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.45703125]], [[78.0]]]}, "model.layers.14.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[31.0]]]}, "model.layers.14.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[56.25]]]}, "model.layers.14.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[26.875]]]}, "model.layers.14.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.14.self_attn.attn.impl.v_cache": {"inputs": [[[31.0]]]}, "model.layers.14.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[55.25]], [[78.0]], [[30.25]]], "outputs": [[[12.3125]], [[1.0]]]}, "model.layers.14.mlp.gate_up_proj": {"inputs": [[[29.25]]], "params": {"weight": [[0.28125]]}}, "model.layers.14.mlp.down_proj": {"inputs": [[[46.5]]], "outputs": [[[40.25]], [[4.8028745941447156e+35]]], "params": {"weight": [[0.6015625]]}}, "model.layers.15.self_attn.qkv_proj": {"inputs": [[[214.0]]], "params": {"weight": [[0.193359375]]}}, "model.layers.15.self_attn.o_proj": {"inputs": [[[11.1875]]], "outputs": [[[40.25]], [[1.129324566731325e+35]]], "params": {"weight": [[0.486328125]]}}, "model.layers.15.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.416015625]], [[94.5]]]}, "model.layers.15.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[17.25]]]}, "model.layers.15.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[66.5]]]}, "model.layers.15.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[31.25]]]}, "model.layers.15.self_attn.attn.impl.k_cache": {"inputs": [[[94.5]]]}, "model.layers.15.self_attn.attn.impl.v_cache": {"inputs": [[[17.25]]]}, "model.layers.15.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[49.25]], [[87.0]], [[15.0625]]], "outputs": [[[11.1875]], [[1.0]]]}, "model.layers.15.mlp.gate_up_proj": {"inputs": [[[27.375]]], "params": {"weight": [[0.328125]]}}, "model.layers.15.mlp.down_proj": {"inputs": [[[48.25]]], "outputs": [[[51.5]], [[8.762000948777522e+34]]], "params": {"weight": [[0.640625]]}}, "model.layers.16.self_attn.qkv_proj": {"inputs": [[[189.0]]], "params": {"weight": [[0.228515625]]}}, "model.layers.16.self_attn.o_proj": {"inputs": [[[12.1875]]], "outputs": [[[35.5]], [[1.1617764220971677e+35]]], "params": {"weight": [[0.41015625]]}}, "model.layers.16.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.498046875]], [[91.0]]]}, "model.layers.16.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[16.25]]]}, "model.layers.16.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[64.5]]]}, "model.layers.16.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[24.375]]]}, "model.layers.16.self_attn.attn.impl.k_cache": {"inputs": [[[91.0]]]}, "model.layers.16.self_attn.attn.impl.v_cache": {"inputs": [[[16.25]]]}, "model.layers.16.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[57.5]], [[87.5]], [[16.25]]], "outputs": [[[12.1875]], [[1.0]]]}, "model.layers.16.mlp.gate_up_proj": {"inputs": [[[30.375]]], "params": {"weight": [[0.30859375]]}}, "model.layers.16.mlp.down_proj": {"inputs": [[[44.0]]], "outputs": [[[36.75]], [[4.8028745941447156e+35]]], "params": {"weight": [[0.6875]]}}, "model.layers.17.self_attn.qkv_proj": {"inputs": [[[193.0]]], "params": {"weight": [[0.1767578125]]}}, "model.layers.17.self_attn.o_proj": {"inputs": [[[12.4375]]], "outputs": [[[40.0]], [[7.885800853899769e+34]]], "params": {"weight": [[0.37890625]]}}, "model.layers.17.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.498046875]], [[80.0]]]}, "model.layers.17.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[16.375]]]}, "model.layers.17.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[44.75]]]}, "model.layers.17.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.0]]]}, "model.layers.17.self_attn.attn.impl.k_cache": {"inputs": [[[80.0]]]}, "model.layers.17.self_attn.attn.impl.v_cache": {"inputs": [[[16.375]]]}, "model.layers.17.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[61.0]], [[80.0]], [[13.625]]], "outputs": [[[12.4375]], [[1.0]]]}, "model.layers.17.mlp.gate_up_proj": {"inputs": [[[31.75]]], "params": {"weight": [[0.298828125]]}}, "model.layers.17.mlp.down_proj": {"inputs": [[[59.25]]], "outputs": [[[27.25]], [[8.956712080972578e+34]]], "params": {"weight": [[0.62890625]]}}, "model.layers.18.self_attn.qkv_proj": {"inputs": [[[153.0]]], "params": {"weight": [[0.189453125]]}}, "model.layers.18.self_attn.o_proj": {"inputs": [[[14.875]]], "outputs": [[[23.375]], [[6.425467362436849e+34]]], "params": {"weight": [[0.2578125]]}}, "model.layers.18.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.54296875]], [[78.0]]]}, "model.layers.18.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[18.375]]]}, "model.layers.18.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[45.0]]]}, "model.layers.18.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[22.75]]]}, "model.layers.18.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.18.self_attn.attn.impl.v_cache": {"inputs": [[[18.375]]]}, "model.layers.18.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[64.0]], [[75.5]], [[18.375]]], "outputs": [[[14.875]], [[1.0]]]}, "model.layers.18.mlp.gate_up_proj": {"inputs": [[[31.625]]], "params": {"weight": [[0.330078125]]}}, "model.layers.18.mlp.down_proj": {"inputs": [[[61.75]]], "outputs": [[[45.25]], [[1.2565358397654283e+36]]], "params": {"weight": [[0.625]]}}, "model.layers.19.self_attn.qkv_proj": {"inputs": [[[160.0]]], "params": {"weight": [[0.1884765625]]}}, "model.layers.19.self_attn.o_proj": {"inputs": [[[14.875]]], "outputs": [[[42.25]], [[1.1838436837459407e+36]]], "params": {"weight": [[0.40625]]}}, "model.layers.19.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5390625]], [[86.5]]]}, "model.layers.19.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[23.625]]]}, "model.layers.19.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[65.5]]]}, "model.layers.19.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[25.625]]]}, "model.layers.19.self_attn.attn.impl.k_cache": {"inputs": [[[86.5]]]}, "model.layers.19.self_attn.attn.impl.v_cache": {"inputs": [[[23.625]]]}, "model.layers.19.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[62.5]], [[86.5]], [[23.625]]], "outputs": [[[14.25]], [[1.0]]]}, "model.layers.19.mlp.gate_up_proj": {"inputs": [[[37.0]]], "params": {"weight": [[0.52734375]]}}, "model.layers.19.mlp.down_proj": {"inputs": [[[376.0]]], "outputs": [[[107.5]], [[1.4668238625360888e+35]]], "params": {"weight": [[0.67578125]]}}, "model.layers.20.self_attn.qkv_proj": {"inputs": [[[0.77734375]]], "params": {"weight": [[0.07275390625]]}}, "model.layers.20.self_attn.o_proj": {"inputs": [[[0.138671875]]], "outputs": [[[0.416015625]], [[8.697097238045836e+34]]], "params": {"weight": [[0.27734375]]}}, "model.layers.20.self_attn.attn.impl.matmul_qk": {"inputs": [[[8.881784197001252e-16]], [[1.199040866595169e-13]]]}, "model.layers.20.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.30078125]]]}, "model.layers.20.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1288.0]]]}, "model.layers.20.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.20.self_attn.attn.impl.k_cache": {"inputs": [[[1.199040866595169e-13]]]}, "model.layers.20.self_attn.attn.impl.v_cache": {"inputs": [[[0.30078125]]]}, "model.layers.20.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[1.0391687510491465e-13]], [[1.199040866595169e-13]], [[0.287109375]]], "outputs": [[[0.138671875]], [[1.0]]]}, "model.layers.20.mlp.gate_up_proj": {"inputs": [[[35.25]]], "params": {"weight": [[0.388671875]]}}, "model.layers.20.mlp.down_proj": {"inputs": [[[77.0]]], "outputs": [[[43.5]], [[6.425467362436849e+34]]], "params": {"weight": [[0.69140625]]}}, "model.layers.21.self_attn.qkv_proj": {"inputs": [[[158.0]]], "params": {"weight": [[0.166015625]]}}, "model.layers.21.self_attn.o_proj": {"inputs": [[[14.5]]], "outputs": [[[45.5]], [[1.1838436837459407e+36]]], "params": {"weight": [[0.4609375]]}}, "model.layers.21.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.59765625]], [[81.5]]]}, "model.layers.21.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[20.5]]]}, "model.layers.21.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[46.0]]]}, "model.layers.21.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[28.0]]]}, "model.layers.21.self_attn.attn.impl.k_cache": {"inputs": [[[81.5]]]}, "model.layers.21.self_attn.attn.impl.v_cache": {"inputs": [[[20.5]]]}, "model.layers.21.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[74.0]], [[74.5]], [[20.5]]], "outputs": [[[14.5]], [[1.0]]]}, "model.layers.21.mlp.gate_up_proj": {"inputs": [[[39.75]]], "params": {"weight": [[0.37890625]]}}, "model.layers.21.mlp.down_proj": {"inputs": [[[130.0]]], "outputs": [[[21.25]], [[9.540845477557746e+34]]], "params": {"weight": [[0.56640625]]}}, "model.layers.22.self_attn.qkv_proj": {"inputs": [[[167.0]]], "params": {"weight": [[0.154296875]]}}, "model.layers.22.self_attn.o_proj": {"inputs": [[[11.6875]]], "outputs": [[[19.5]], [[1.2565358397654283e+36]]], "params": {"weight": [[0.28515625]]}}, "model.layers.22.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5625]], [[73.5]]]}, "model.layers.22.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[17.0]]]}, "model.layers.22.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[59.0]]]}, "model.layers.22.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[20.125]]]}, "model.layers.22.self_attn.attn.impl.k_cache": {"inputs": [[[73.5]]]}, "model.layers.22.self_attn.attn.impl.v_cache": {"inputs": [[[17.0]]]}, "model.layers.22.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[71.5]], [[71.5]], [[17.0]]], "outputs": [[[10.1875]], [[1.0]]]}, "model.layers.22.mlp.gate_up_proj": {"inputs": [[[41.75]]], "params": {"weight": [[0.208984375]]}}, "model.layers.22.mlp.down_proj": {"inputs": [[[107.5]]], "outputs": [[[33.25]], [[2.7389365928771216e+35]]], "params": {"weight": [[0.578125]]}}, "model.layers.23.self_attn.qkv_proj": {"inputs": [[[1.1328125]]], "params": {"weight": [[0.04541015625]]}}, "model.layers.23.self_attn.o_proj": {"inputs": [[[0.06591796875]]], "outputs": [[[0.12890625]], [[1.8484576816383986e+36]]], "params": {"weight": [[0.11865234375]]}}, "model.layers.23.self_attn.attn.impl.matmul_qk": {"inputs": [[[6.002143226879753e-16]], [[1.0169642905566434e-13]]]}, "model.layers.23.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.193359375]]]}, "model.layers.23.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1288.0]]]}, "model.layers.23.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.23.self_attn.attn.impl.k_cache": {"inputs": [[[1.0169642905566434e-13]]]}, "model.layers.23.self_attn.attn.impl.v_cache": {"inputs": [[[0.193359375]]]}, "model.layers.23.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[7.72715225139109e-14]], [[1.0169642905566434e-13]], [[0.173828125]]], "outputs": [[[0.06591796875]], [[1.0]]]}, "model.layers.23.mlp.gate_up_proj": {"inputs": [[[43.75]]], "params": {"weight": [[0.3515625]]}}, "model.layers.23.mlp.down_proj": {"inputs": [[[163.0]]], "outputs": [[[13.0625]], [[1.0644208559996397e+35]]], "params": {"weight": [[0.484375]]}}, "model.layers.24.self_attn.qkv_proj": {"inputs": [[[1.0625]]], "params": {"weight": [[0.044189453125]]}}, "model.layers.24.self_attn.o_proj": {"inputs": [[[0.0615234375]]], "outputs": [[[0.279296875]], [[1.116343824584988e+36]]], "params": {"weight": [[0.1181640625]]}}, "model.layers.24.self_attn.attn.impl.matmul_qk": {"inputs": [[[5.655198531684391e-16]], [[8.526512829121202e-14]]]}, "model.layers.24.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.197265625]]]}, "model.layers.24.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1288.0]]]}, "model.layers.24.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.24.self_attn.attn.impl.k_cache": {"inputs": [[[8.526512829121202e-14]]]}, "model.layers.24.self_attn.attn.impl.v_cache": {"inputs": [[[0.197265625]]]}, "model.layers.24.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[7.682743330406083e-14]], [[8.038014698286133e-14]], [[0.197265625]]], "outputs": [[[0.0615234375]], [[1.0]]]}, "model.layers.24.mlp.gate_up_proj": {"inputs": [[[43.25]]], "params": {"weight": [[0.2333984375]]}}, "model.layers.24.mlp.down_proj": {"inputs": [[[103.0]]], "outputs": [[[15.25]], [[8.697097238045836e+34]]], "params": {"weight": [[0.48828125]]}}, "model.layers.25.self_attn.qkv_proj": {"inputs": [[[178.0]]], "params": {"weight": [[0.220703125]]}}, "model.layers.25.self_attn.o_proj": {"inputs": [[[11.0]]], "outputs": [[[8.3125]], [[1.116343824584988e+36]]], "params": {"weight": [[0.38671875]]}}, "model.layers.25.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.6015625]], [[78.0]]]}, "model.layers.25.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.8125]]]}, "model.layers.25.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[35.5]]]}, "model.layers.25.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[20.625]]]}, "model.layers.25.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.25.self_attn.attn.impl.v_cache": {"inputs": [[[15.8125]]]}, "model.layers.25.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[80.0]], [[72.0]], [[15.3125]]], "outputs": [[[10.875]], [[1.0]]]}, "model.layers.25.mlp.gate_up_proj": {"inputs": [[[47.75]]], "params": {"weight": [[0.28515625]]}}, "model.layers.25.mlp.down_proj": {"inputs": [[[113.5]]], "outputs": [[[29.625]], [[1.4149008939507405e+35]]], "params": {"weight": [[0.61328125]]}}, "model.layers.26.self_attn.qkv_proj": {"inputs": [[[1.6640625]]], "params": {"weight": [[0.058349609375]]}}, "model.layers.26.self_attn.o_proj": {"inputs": [[[0.08544921875]]], "outputs": [[[0.201171875]], [[9.540845477557746e+34]]], "params": {"weight": [[0.166015625]]}}, "model.layers.26.self_attn.attn.impl.matmul_qk": {"inputs": [[[7.042977312465837e-16]], [[1.0791367799356522e-13]]]}, "model.layers.26.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.28515625]]]}, "model.layers.26.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1288.0]]]}, "model.layers.26.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.26.self_attn.attn.impl.k_cache": {"inputs": [[[1.0791367799356522e-13]]]}, "model.layers.26.self_attn.attn.impl.v_cache": {"inputs": [[[0.28515625]]]}, "model.layers.26.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[9.414691248821327e-14]], [[1.0791367799356522e-13]], [[0.28515625]]], "outputs": [[[0.08544921875]], [[1.0]]]}, "model.layers.26.mlp.gate_up_proj": {"inputs": [[[55.0]]], "params": {"weight": [[0.34765625]]}}, "model.layers.26.mlp.down_proj": {"inputs": [[[336.0]]], "outputs": [[[102.0]], [[1.129324566731325e+35]]], "params": {"weight": [[0.419921875]]}}, "model.layers.27.self_attn.qkv_proj": {"inputs": [[[1.8359375]]], "params": {"weight": [[0.06689453125]]}}, "model.layers.27.self_attn.o_proj": {"inputs": [[[0.1259765625]]], "outputs": [[[0.435546875]], [[1.116343824584988e+36]]], "params": {"weight": [[0.1640625]]}}, "model.layers.27.self_attn.attn.impl.matmul_qk": {"inputs": [[[8.222589276130066e-16]], [[1.412203687323199e-13]]]}, "model.layers.27.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.28515625]]]}, "model.layers.27.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1288.0]]]}, "model.layers.27.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.27.self_attn.attn.impl.k_cache": {"inputs": [[[1.412203687323199e-13]]]}, "model.layers.27.self_attn.attn.impl.v_cache": {"inputs": [[[0.28515625]]]}, "model.layers.27.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[1.199040866595169e-13]], [[1.412203687323199e-13]], [[0.28515625]]], "outputs": [[[0.1259765625]], [[1.0]]]}, "model.layers.27.mlp.gate_up_proj": {"inputs": [[[62.5]]], "params": {"weight": [[0.6640625]]}}, "model.layers.27.mlp.down_proj": {"inputs": [[[155.0]]], "outputs": [[[18.75]], [[1.129324566731325e+35]]], "params": {"weight": [[0.5546875]]}}, "model.layers.28.self_attn.qkv_proj": {"inputs": [[[171.0]]], "params": {"weight": [[0.228515625]]}}, "model.layers.28.self_attn.o_proj": {"inputs": [[[15.8125]]], "outputs": [[[9.4375]], [[1.492785346828763e+35]]], "params": {"weight": [[0.87109375]]}}, "model.layers.28.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.546875]], [[75.5]]]}, "model.layers.28.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[25.25]]]}, "model.layers.28.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[25.25]]]}, "model.layers.28.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.0]]]}, "model.layers.28.self_attn.attn.impl.k_cache": {"inputs": [[[75.5]]]}, "model.layers.28.self_attn.attn.impl.v_cache": {"inputs": [[[25.25]]]}, "model.layers.28.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[67.5]], [[72.0]], [[25.25]]], "outputs": [[[14.9375]], [[1.0]]]}, "model.layers.28.mlp.gate_up_proj": {"inputs": [[[56.5]]], "params": {"weight": [[0.2451171875]]}}, "model.layers.28.mlp.down_proj": {"inputs": [[[139.0]]], "outputs": [[[28.875]], [[1.4798046046824259e+35]]], "params": {"weight": [[0.5859375]]}}, "model.layers.29.self_attn.qkv_proj": {"inputs": [[[5.53125]]], "params": {"weight": [[0.10546875]]}}, "model.layers.29.self_attn.o_proj": {"inputs": [[[0.46875]]], "outputs": [[[2.609375]], [[1.031969000633797e+35]]], "params": {"weight": [[0.2197265625]]}}, "model.layers.29.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.3175905639050143e-15]], [[4.725109192804666e-13]]]}, "model.layers.29.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.60546875]]]}, "model.layers.29.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1288.0]]]}, "model.layers.29.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.29.self_attn.attn.impl.k_cache": {"inputs": [[[4.725109192804666e-13]]]}, "model.layers.29.self_attn.attn.impl.v_cache": {"inputs": [[[0.60546875]]]}, "model.layers.29.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[3.2152058793144533e-13]], [[4.725109192804666e-13]], [[0.58984375]]], "outputs": [[[0.46875]], [[1.0]]]}, "model.layers.29.mlp.gate_up_proj": {"inputs": [[[59.25]]], "params": {"weight": [[0.326171875]]}}, "model.layers.29.mlp.down_proj": {"inputs": [[[157.0]]], "outputs": [[[37.25]], [[1.311054956780044e+35]]], "params": {"weight": [[0.57421875]]}}, "model.layers.30.self_attn.qkv_proj": {"inputs": [[[181.0]]], "params": {"weight": [[0.193359375]]}}, "model.layers.30.self_attn.o_proj": {"inputs": [[[26.25]]], "outputs": [[[20.125]], [[1.1838436837459407e+36]]], "params": {"weight": [[0.77734375]]}}, "model.layers.30.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.55078125]], [[78.5]]]}, "model.layers.30.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[38.75]]]}, "model.layers.30.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[33.75]]]}, "model.layers.30.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[35.5]]]}, "model.layers.30.self_attn.attn.impl.k_cache": {"inputs": [[[78.5]]]}, "model.layers.30.self_attn.attn.impl.v_cache": {"inputs": [[[38.75]]]}, "model.layers.30.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[68.5]], [[75.0]], [[38.0]]], "outputs": [[[21.25]], [[1.0]]]}, "model.layers.30.mlp.gate_up_proj": {"inputs": [[[62.0]]], "params": {"weight": [[0.33984375]]}}, "model.layers.30.mlp.down_proj": {"inputs": [[[138.0]]], "outputs": [[[37.5]], [[1.4149008939507405e+35]]], "params": {"weight": [[0.55078125]]}}, "model.layers.31.self_attn.qkv_proj": {"inputs": [[[171.0]]], "params": {"weight": [[0.265625]]}}, "model.layers.31.self_attn.o_proj": {"inputs": [[[19.5]]], "outputs": [[[38.0]], [[1.0644208559996397e+35]]], "params": {"weight": [[0.326171875]]}}, "model.layers.31.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.60546875]], [[78.0]]]}, "model.layers.31.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[23.5]]]}, "model.layers.31.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[53.0]]]}, "model.layers.31.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[24.375]]]}, "model.layers.31.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.31.self_attn.attn.impl.v_cache": {"inputs": [[[23.5]]]}, "model.layers.31.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[74.5]], [[73.0]], [[22.5]]], "outputs": [[[18.625]], [[1.0]]]}, "model.layers.31.mlp.gate_up_proj": {"inputs": [[[63.75]]], "params": {"weight": [[0.302734375]]}}, "model.layers.31.mlp.down_proj": {"inputs": [[[176.0]]], "outputs": [[[41.25]], [[1.1838436837459407e+36]]], "params": {"weight": [[0.451171875]]}}, "model.layers.32.self_attn.qkv_proj": {"inputs": [[[174.0]]], "params": {"weight": [[0.259765625]]}}, "model.layers.32.self_attn.o_proj": {"inputs": [[[27.625]]], "outputs": [[[55.75]], [[2.7389365928771216e+35]]], "params": {"weight": [[0.75390625]]}}, "model.layers.32.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.7734375]], [[82.0]]]}, "model.layers.32.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[32.75]]]}, "model.layers.32.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[46.0]]]}, "model.layers.32.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[27.625]]]}, "model.layers.32.self_attn.attn.impl.k_cache": {"inputs": [[[82.0]]]}, "model.layers.32.self_attn.attn.impl.v_cache": {"inputs": [[[32.75]]]}, "model.layers.32.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[96.0]], [[77.5]], [[30.125]]], "outputs": [[[24.125]], [[1.0]]]}, "model.layers.32.mlp.gate_up_proj": {"inputs": [[[68.5]]], "params": {"weight": [[0.43359375]]}}, "model.layers.32.mlp.down_proj": {"inputs": [[[201.0]]], "outputs": [[[49.75]], [[1.1838436837459407e+36]]], "params": {"weight": [[0.4921875]]}}, "model.layers.33.self_attn.qkv_proj": {"inputs": [[[205.0]]], "params": {"weight": [[0.20703125]]}}, "model.layers.33.self_attn.o_proj": {"inputs": [[[30.25]]], "outputs": [[[38.75]], [[4.8028745941447156e+35]]], "params": {"weight": [[0.47265625]]}}, "model.layers.33.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.640625]], [[93.0]]]}, "model.layers.33.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[32.75]]]}, "model.layers.33.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[37.75]]]}, "model.layers.33.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[30.25]]]}, "model.layers.33.self_attn.attn.impl.k_cache": {"inputs": [[[93.0]]]}, "model.layers.33.self_attn.attn.impl.v_cache": {"inputs": [[[32.75]]]}, "model.layers.33.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[78.0]], [[90.5]], [[29.5]]], "outputs": [[[27.75]], [[1.0]]]}, "model.layers.33.mlp.gate_up_proj": {"inputs": [[[70.5]]], "params": {"weight": [[0.384765625]]}}, "model.layers.33.mlp.down_proj": {"inputs": [[[268.0]]], "outputs": [[[92.0]], [[1.4149008939507405e+35]]], "params": {"weight": [[0.5234375]]}}, "model.layers.34.self_attn.qkv_proj": {"inputs": [[[187.0]]], "params": {"weight": [[0.310546875]]}}, "model.layers.34.self_attn.o_proj": {"inputs": [[[36.5]]], "outputs": [[[99.5]], [[9.540845477557746e+34]]], "params": {"weight": [[0.353515625]]}}, "model.layers.34.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.625]], [[83.5]]]}, "model.layers.34.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[40.25]]]}, "model.layers.34.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[40.0]]]}, "model.layers.34.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[33.5]]]}, "model.layers.34.self_attn.attn.impl.k_cache": {"inputs": [[[83.5]]]}, "model.layers.34.self_attn.attn.impl.v_cache": {"inputs": [[[40.25]]]}, "model.layers.34.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[81.5]], [[80.5]], [[40.25]]], "outputs": [[[36.5]], [[1.0]]]}, "model.layers.34.mlp.gate_up_proj": {"inputs": [[[82.5]]], "params": {"weight": [[0.294921875]]}}, "model.layers.34.mlp.down_proj": {"inputs": [[[282.0]]], "outputs": [[[86.5]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.4921875]]}}, "model.layers.35.self_attn.qkv_proj": {"inputs": [[[199.0]]], "params": {"weight": [[0.25]]}}, "model.layers.35.self_attn.o_proj": {"inputs": [[[29.25]]], "outputs": [[[79.5]], [[1.1838436837459407e+36]]], "params": {"weight": [[0.451171875]]}}, "model.layers.35.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.58203125]], [[87.5]]]}, "model.layers.35.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[33.0]]]}, "model.layers.35.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[66.5]]]}, "model.layers.35.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[28.5]]]}, "model.layers.35.self_attn.attn.impl.k_cache": {"inputs": [[[87.5]]]}, "model.layers.35.self_attn.attn.impl.v_cache": {"inputs": [[[33.0]]]}, "model.layers.35.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[75.5]], [[85.5]], [[31.375]]], "outputs": [[[29.25]], [[1.0]]]}, "model.layers.35.mlp.gate_up_proj": {"inputs": [[[105.0]]], "params": {"weight": [[0.3671875]]}}, "model.layers.35.mlp.down_proj": {"inputs": [[[398.0]]], "outputs": [[[108.0]], [[7.885800853899769e+34]]], "params": {"weight": [[0.5078125]]}}, "model.layers.36.self_attn.qkv_proj": {"inputs": [[[202.0]]], "params": {"weight": [[0.2353515625]]}}, "model.layers.36.self_attn.o_proj": {"inputs": [[[38.25]]], "outputs": [[[78.0]], [[1.1838436837459407e+36]]], "params": {"weight": [[0.43359375]]}}, "model.layers.36.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.6015625]], [[94.5]]]}, "model.layers.36.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[48.25]]]}, "model.layers.36.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[40.75]]]}, "model.layers.36.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[42.5]]]}, "model.layers.36.self_attn.attn.impl.k_cache": {"inputs": [[[94.5]]]}, "model.layers.36.self_attn.attn.impl.v_cache": {"inputs": [[[48.25]]]}, "model.layers.36.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[78.5]], [[90.0]], [[42.5]]], "outputs": [[[35.5]], [[1.0]]]}, "model.layers.36.mlp.gate_up_proj": {"inputs": [[[112.0]]], "params": {"weight": [[0.392578125]]}}, "model.layers.36.mlp.down_proj": {"inputs": [[[616.0]]], "outputs": [[[96.5]], [[1.2591319881946957e+35]]], "params": {"weight": [[0.4921875]]}}, "model.layers.37.self_attn.qkv_proj": {"inputs": [[[217.0]]], "params": {"weight": [[0.234375]]}}, "model.layers.37.self_attn.o_proj": {"inputs": [[[48.0]]], "outputs": [[[91.0]], [[1.1098534535118194e+35]]], "params": {"weight": [[0.41015625]]}}, "model.layers.37.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.8046875]], [[99.0]]]}, "model.layers.37.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[54.0]]]}, "model.layers.37.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[44.5]]]}, "model.layers.37.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[48.0]]]}, "model.layers.37.self_attn.attn.impl.k_cache": {"inputs": [[[99.0]]]}, "model.layers.37.self_attn.attn.impl.v_cache": {"inputs": [[[54.0]]]}, "model.layers.37.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[103.0]], [[97.0]], [[54.0]]], "outputs": [[[47.0]], [[1.0]]]}, "model.layers.37.mlp.gate_up_proj": {"inputs": [[[142.0]]], "params": {"weight": [[0.25390625]]}}, "model.layers.37.mlp.down_proj": {"inputs": [[[1400.0]]], "outputs": [[[780.0]], [[1.311054956780044e+35]]], "params": {"weight": [[0.54296875]]}}, "model.layers.38.self_attn.qkv_proj": {"inputs": [[[169.0]]], "params": {"weight": [[0.2001953125]]}}, "model.layers.38.self_attn.o_proj": {"inputs": [[[45.0]]], "outputs": [[[201.0]], [[8.632193527314151e+34]]], "params": {"weight": [[0.408203125]]}}, "model.layers.38.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.6328125]], [[90.0]]]}, "model.layers.38.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[70.5]]]}, "model.layers.38.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[93.5]]]}, "model.layers.38.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[57.25]]]}, "model.layers.38.self_attn.attn.impl.k_cache": {"inputs": [[[90.0]]]}, "model.layers.38.self_attn.attn.impl.v_cache": {"inputs": [[[70.5]]]}, "model.layers.38.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[83.5]], [[84.0]], [[70.5]]], "outputs": [[[45.0]], [[1.0]]]}, "model.layers.38.mlp.gate_up_proj": {"inputs": [[[179.0]]], "params": {"weight": [[0.34765625]]}}, "model.layers.38.mlp.down_proj": {"inputs": [[[1192.0]]], "outputs": [[[636.0]], [[1.1617764220971677e+35]]], "params": {"weight": [[0.41796875]]}}, "model.layers.39.self_attn.qkv_proj": {"inputs": [[[272.0]]], "params": {"weight": [[0.1904296875]]}}, "model.layers.39.self_attn.o_proj": {"inputs": [[[70.0]]], "outputs": [[[366.0]], [[1.0384593717069655e+35]]], "params": {"weight": [[0.48046875]]}}, "model.layers.39.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.84375]], [[101.5]]]}, "model.layers.39.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[78.5]]]}, "model.layers.39.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[44.25]]]}, "model.layers.39.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[70.0]]]}, "model.layers.39.self_attn.attn.impl.k_cache": {"inputs": [[[101.5]]]}, "model.layers.39.self_attn.attn.impl.v_cache": {"inputs": [[[78.5]]]}, "model.layers.39.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[123.0]], [[101.5]], [[69.0]]], "outputs": [[[63.75]], [[1.0]]]}, "model.layers.39.mlp.gate_up_proj": {"inputs": [[[474.0]]], "params": {"weight": [[0.55078125]]}}, "model.layers.39.mlp.down_proj": {"inputs": [[[10176.0]]], "outputs": [[[13696.0]], [[1.4798046046824259e+35]]], "params": {"weight": [[0.58984375]]}}, "lm_head": {"inputs": [[[1368.0]]], "params": {"weight": [[0.337890625]]}}}}