{"GlobalRank": null, "LocalRank": 0, "Mode": "DynamicRange", "Nodes": {"model.layers.0.self_attn.qkv_proj": {"inputs": [[[692.0]]], "params": {"weight": [[0.2734375]]}}, "model.layers.0.self_attn.o_proj": {"inputs": [[[35.0]]], "outputs": [[[34.75]], [[7.643060975763266e+36]]], "params": {"weight": [[0.546875]]}}, "model.layers.0.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.21875]], [[200.0]]]}, "model.layers.0.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[62.25]]]}, "model.layers.0.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[282.0]]]}, "model.layers.0.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[62.25]]]}, "model.layers.0.self_attn.attn.impl.k_cache": {"inputs": [[[200.0]]]}, "model.layers.0.self_attn.attn.impl.v_cache": {"inputs": [[[62.25]]]}, "model.layers.0.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[156.0]], [[200.0]], [[62.25]]], "outputs": [[[35.0]], [[1.0]]]}, "model.layers.0.mlp.gate_up_proj": {"inputs": [[[144.0]]], "params": {"weight": [[0.82421875]]}}, "model.layers.0.mlp.down_proj": {"inputs": [[[192.0]]], "outputs": [[[113.5]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.9453125]]}}, "model.layers.1.self_attn.qkv_proj": {"inputs": [[[164.0]]], "params": {"weight": [[0.466796875]]}}, "model.layers.1.self_attn.o_proj": {"inputs": [[[10.25]]], "outputs": [[[9.5625]], [[8.43229009826056e+36]]], "params": {"weight": [[0.42578125]]}}, "model.layers.1.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.33203125]], [[118.5]]]}, "model.layers.1.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[13.625]]]}, "model.layers.1.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[152.0]]]}, "model.layers.1.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[53.75]]]}, "model.layers.1.self_attn.attn.impl.k_cache": {"inputs": [[[118.5]]]}, "model.layers.1.self_attn.attn.impl.v_cache": {"inputs": [[[13.625]]]}, "model.layers.1.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[41.25]], [[118.0]], [[13.625]]], "outputs": [[[10.25]], [[1.0]]]}, "model.layers.1.mlp.gate_up_proj": {"inputs": [[[94.5]]], "params": {"weight": [[0.423828125]]}}, "model.layers.1.mlp.down_proj": {"inputs": [[[132.0]]], "outputs": [[[50.5]], [[3.372916039304224e+37]]], "params": {"weight": [[0.392578125]]}}, "model.layers.2.self_attn.qkv_proj": {"inputs": [[[117.0]]], "params": {"weight": [[0.408203125]]}}, "model.layers.2.self_attn.o_proj": {"inputs": [[[9.625]]], "outputs": [[[13.1875]], [[1.26276659599567e+37]]], "params": {"weight": [[0.478515625]]}}, "model.layers.2.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.2373046875]], [[83.5]]]}, "model.layers.2.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[10.9375]]]}, "model.layers.2.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[161.0]]]}, "model.layers.2.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[56.0]]]}, "model.layers.2.self_attn.attn.impl.k_cache": {"inputs": [[[83.5]]]}, "model.layers.2.self_attn.attn.impl.v_cache": {"inputs": [[[10.9375]]]}, "model.layers.2.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[30.625]], [[83.5]], [[10.9375]]], "outputs": [[[9.625]], [[1.0]]]}, "model.layers.2.mlp.gate_up_proj": {"inputs": [[[54.25]]], "params": {"weight": [[0.55078125]]}}, "model.layers.2.mlp.down_proj": {"inputs": [[[2688.0]]], "outputs": [[[1992.0]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.66796875]]}}, "model.layers.3.self_attn.qkv_proj": {"inputs": [[[110.0]]], "params": {"weight": [[0.4375]]}}, "model.layers.3.self_attn.o_proj": {"inputs": [[[9.5]]], "outputs": [[[8.5]], [[1.1796898462591128e+37]]], "params": {"weight": [[0.32421875]]}}, "model.layers.3.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.384765625]], [[80.0]]]}, "model.layers.3.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[11.1875]]]}, "model.layers.3.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[372.0]]]}, "model.layers.3.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[61.0]]]}, "model.layers.3.self_attn.attn.impl.k_cache": {"inputs": [[[80.0]]]}, "model.layers.3.self_attn.attn.impl.v_cache": {"inputs": [[[11.1875]]]}, "model.layers.3.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[49.0]], [[78.5]], [[11.1875]]], "outputs": [[[9.5]], [[1.0]]]}, "model.layers.3.mlp.gate_up_proj": {"inputs": [[[22.125]]], "params": {"weight": [[0.251953125]]}}, "model.layers.3.mlp.down_proj": {"inputs": [[[76.5]]], "outputs": [[[89.0]], [[3.4559927890407813e+37]]], "params": {"weight": [[0.5390625]]}}, "model.layers.4.self_attn.qkv_proj": {"inputs": [[[145.0]]], "params": {"weight": [[0.2021484375]]}}, "model.layers.4.self_attn.o_proj": {"inputs": [[[10.3125]]], "outputs": [[[7.03125]], [[3.4559927890407813e+37]]], "params": {"weight": [[0.359375]]}}, "model.layers.4.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.42578125]], [[76.5]]]}, "model.layers.4.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.3125]]]}, "model.layers.4.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[668.0]]]}, "model.layers.4.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[105.0]]]}, "model.layers.4.self_attn.attn.impl.k_cache": {"inputs": [[[76.5]]]}, "model.layers.4.self_attn.attn.impl.v_cache": {"inputs": [[[14.3125]]]}, "model.layers.4.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[54.25]], [[76.0]], [[14.3125]]], "outputs": [[[9.8125]], [[1.0]]]}, "model.layers.4.mlp.gate_up_proj": {"inputs": [[[28.75]]], "params": {"weight": [[0.384765625]]}}, "model.layers.4.mlp.down_proj": {"inputs": [[[2144.0]]], "outputs": [[[2496.0]], [[1.8276884942042593e+37]]], "params": {"weight": [[0.59765625]]}}, "model.layers.5.self_attn.qkv_proj": {"inputs": [[[182.0]]], "params": {"weight": [[0.59765625]]}}, "model.layers.5.self_attn.o_proj": {"inputs": [[[10.3125]]], "outputs": [[[11.5625]], [[3.372916039304224e+37]]], "params": {"weight": [[0.453125]]}}, "model.layers.5.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.431640625]], [[72.5]]]}, "model.layers.5.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.4375]]]}, "model.layers.5.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[644.0]]]}, "model.layers.5.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[106.0]]]}, "model.layers.5.self_attn.attn.impl.k_cache": {"inputs": [[[72.5]]]}, "model.layers.5.self_attn.attn.impl.v_cache": {"inputs": [[[15.4375]]]}, "model.layers.5.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[54.25]], [[72.5]], [[15.4375]]], "outputs": [[[10.3125]], [[1.0]]]}, "model.layers.5.mlp.gate_up_proj": {"inputs": [[[103.5]]], "params": {"weight": [[0.400390625]]}}, "model.layers.5.mlp.down_proj": {"inputs": [[[28032.0]]], "outputs": [[[22272.0]], [[3.4726081389880927e+37]]], "params": {"weight": [[0.76171875]]}}, "model.layers.6.self_attn.qkv_proj": {"inputs": [[[141.0]]], "params": {"weight": [[0.259765625]]}}, "model.layers.6.self_attn.o_proj": {"inputs": [[[9.4375]]], "outputs": [[[17.25]], [[2.857840190937569e+37]]], "params": {"weight": [[0.353515625]]}}, "model.layers.6.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.458984375]], [[77.0]]]}, "model.layers.6.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[24.125]]]}, "model.layers.6.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[45.75]]]}, "model.layers.6.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.625]]]}, "model.layers.6.self_attn.attn.impl.k_cache": {"inputs": [[[77.0]]]}, "model.layers.6.self_attn.attn.impl.v_cache": {"inputs": [[[24.125]]]}, "model.layers.6.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[58.25]], [[72.5]], [[24.125]]], "outputs": [[[9.4375]], [[1.0]]]}, "model.layers.6.mlp.gate_up_proj": {"inputs": [[[52.75]]], "params": {"weight": [[0.314453125]]}}, "model.layers.6.mlp.down_proj": {"inputs": [[[49.25]]], "outputs": [[[28.125]], [[1.6881195546468432e+38]]], "params": {"weight": [[0.44140625]]}}, "model.layers.7.self_attn.qkv_proj": {"inputs": [[[152.0]]], "params": {"weight": [[0.22265625]]}}, "model.layers.7.self_attn.o_proj": {"inputs": [[[10.0]]], "outputs": [[[14.75]], [[1.8276884942042593e+37]]], "params": {"weight": [[0.48828125]]}}, "model.layers.7.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.453125]], [[70.0]]]}, "model.layers.7.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.1875]]]}, "model.layers.7.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[32.75]]]}, "model.layers.7.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[18.875]]]}, "model.layers.7.self_attn.attn.impl.k_cache": {"inputs": [[[70.0]]]}, "model.layers.7.self_attn.attn.impl.v_cache": {"inputs": [[[12.1875]]]}, "model.layers.7.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[60.25]], [[66.0]], [[12.1875]]], "outputs": [[[9.25]], [[1.0]]]}, "model.layers.7.mlp.gate_up_proj": {"inputs": [[[33.5]]], "params": {"weight": [[0.3125]]}}, "model.layers.7.mlp.down_proj": {"inputs": [[[61.0]]], "outputs": [[[21.5]], [[7.643060975763266e+36]]], "params": {"weight": [[0.5]]}}, "model.layers.8.self_attn.qkv_proj": {"inputs": [[[207.0]]], "params": {"weight": [[0.2041015625]]}}, "model.layers.8.self_attn.o_proj": {"inputs": [[[9.5625]]], "outputs": [[[15.125]], [[4.8599898595885987e+36]]], "params": {"weight": [[0.43359375]]}}, "model.layers.8.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.51171875]], [[77.5]]]}, "model.layers.8.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[16.125]]]}, "model.layers.8.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[51.0]]]}, "model.layers.8.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[18.0]]]}, "model.layers.8.self_attn.attn.impl.k_cache": {"inputs": [[[77.5]]]}, "model.layers.8.self_attn.attn.impl.v_cache": {"inputs": [[[16.125]]]}, "model.layers.8.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[65.5]], [[72.5]], [[14.375]]], "outputs": [[[8.4375]], [[1.0]]]}, "model.layers.8.mlp.gate_up_proj": {"inputs": [[[29.0]]], "params": {"weight": [[0.28515625]]}}, "model.layers.8.mlp.down_proj": {"inputs": [[[42.5]]], "outputs": [[[18.0]], [[1.6881195546468432e+38]]], "params": {"weight": [[0.58203125]]}}, "model.layers.9.self_attn.qkv_proj": {"inputs": [[[206.0]]], "params": {"weight": [[0.302734375]]}}, "model.layers.9.self_attn.o_proj": {"inputs": [[[10.5]]], "outputs": [[[18.5]], [[1.2544589210220144e+37]]], "params": {"weight": [[0.333984375]]}}, "model.layers.9.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.486328125]], [[81.0]]]}, "model.layers.9.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.375]]]}, "model.layers.9.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[30.125]]]}, "model.layers.9.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[16.625]]]}, "model.layers.9.self_attn.attn.impl.k_cache": {"inputs": [[[81.0]]]}, "model.layers.9.self_attn.attn.impl.v_cache": {"inputs": [[[12.375]]]}, "model.layers.9.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[60.25]], [[74.0]], [[12.375]]], "outputs": [[[9.3125]], [[1.0]]]}, "model.layers.9.mlp.gate_up_proj": {"inputs": [[[26.0]]], "params": {"weight": [[0.3359375]]}}, "model.layers.9.mlp.down_proj": {"inputs": [[[39.0]]], "outputs": [[[17.875]], [[1.0799977465752441e+37]]], "params": {"weight": [[0.5390625]]}}, "model.layers.10.self_attn.qkv_proj": {"inputs": [[[219.0]]], "params": {"weight": [[0.267578125]]}}, "model.layers.10.self_attn.o_proj": {"inputs": [[[11.5]]], "outputs": [[[17.625]], [[2.857840190937569e+37]]], "params": {"weight": [[0.54296875]]}}, "model.layers.10.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.49609375]], [[82.5]]]}, "model.layers.10.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.8125]]]}, "model.layers.10.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[39.5]]]}, "model.layers.10.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[25.5]]]}, "model.layers.10.self_attn.attn.impl.k_cache": {"inputs": [[[82.5]]]}, "model.layers.10.self_attn.attn.impl.v_cache": {"inputs": [[[12.8125]]]}, "model.layers.10.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[70.0]], [[76.5]], [[12.8125]]], "outputs": [[[11.5]], [[1.0]]]}, "model.layers.10.mlp.gate_up_proj": {"inputs": [[[26.5]]], "params": {"weight": [[0.341796875]]}}, "model.layers.10.mlp.down_proj": {"inputs": [[[36.5]]], "outputs": [[[22.25]], [[8.43229009826056e+36]]], "params": {"weight": [[0.57421875]]}}, "model.layers.11.self_attn.qkv_proj": {"inputs": [[[250.0]]], "params": {"weight": [[0.28125]]}}, "model.layers.11.self_attn.o_proj": {"inputs": [[[12.4375]]], "outputs": [[[21.5]], [[3.4726081389880927e+37]]], "params": {"weight": [[0.359375]]}}, "model.layers.11.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.51171875]], [[80.5]]]}, "model.layers.11.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.5]]]}, "model.layers.11.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[40.5]]]}, "model.layers.11.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[20.875]]]}, "model.layers.11.self_attn.attn.impl.k_cache": {"inputs": [[[80.5]]]}, "model.layers.11.self_attn.attn.impl.v_cache": {"inputs": [[[15.5]]]}, "model.layers.11.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[70.0]], [[79.5]], [[15.5]]], "outputs": [[[11.25]], [[1.0]]]}, "model.layers.11.mlp.gate_up_proj": {"inputs": [[[26.5]]], "params": {"weight": [[0.349609375]]}}, "model.layers.11.mlp.down_proj": {"inputs": [[[42.25]]], "outputs": [[[25.125]], [[3.4726081389880927e+37]]], "params": {"weight": [[0.443359375]]}}, "model.layers.12.self_attn.qkv_proj": {"inputs": [[[322.0]]], "params": {"weight": [[0.2734375]]}}, "model.layers.12.self_attn.o_proj": {"inputs": [[[11.0]]], "outputs": [[[21.25]], [[4.8599898595885987e+36]]], "params": {"weight": [[0.431640625]]}}, "model.layers.12.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.4765625]], [[78.0]]]}, "model.layers.12.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[13.5]]]}, "model.layers.12.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[41.25]]]}, "model.layers.12.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[19.875]]]}, "model.layers.12.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.12.self_attn.attn.impl.v_cache": {"inputs": [[[13.5]]]}, "model.layers.12.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.0]], [[75.5]], [[13.5]]], "outputs": [[[11.0]], [[1.0]]]}, "model.layers.12.mlp.gate_up_proj": {"inputs": [[[31.75]]], "params": {"weight": [[0.345703125]]}}, "model.layers.12.mlp.down_proj": {"inputs": [[[38.25]]], "outputs": [[[23.375]], [[3.0705166702631557e+38]]], "params": {"weight": [[0.482421875]]}}, "model.layers.13.self_attn.qkv_proj": {"inputs": [[[248.0]]], "params": {"weight": [[0.353515625]]}}, "model.layers.13.self_attn.o_proj": {"inputs": [[[11.0]]], "outputs": [[[21.625]], [[3.372916039304224e+37]]], "params": {"weight": [[0.71875]]}}, "model.layers.13.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.515625]], [[81.5]]]}, "model.layers.13.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.75]]]}, "model.layers.13.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[47.5]]]}, "model.layers.13.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.625]]]}, "model.layers.13.self_attn.attn.impl.k_cache": {"inputs": [[[81.5]]]}, "model.layers.13.self_attn.attn.impl.v_cache": {"inputs": [[[14.75]]]}, "model.layers.13.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[67.5]], [[78.5]], [[14.1875]]], "outputs": [[[10.125]], [[1.0]]]}, "model.layers.13.mlp.gate_up_proj": {"inputs": [[[27.0]]], "params": {"weight": [[0.27734375]]}}, "model.layers.13.mlp.down_proj": {"inputs": [[[40.75]]], "outputs": [[[27.875]], [[1.237843571074703e+37]]], "params": {"weight": [[0.56640625]]}}, "model.layers.14.self_attn.qkv_proj": {"inputs": [[[244.0]]], "params": {"weight": [[0.1708984375]]}}, "model.layers.14.self_attn.o_proj": {"inputs": [[[13.5625]]], "outputs": [[[31.375]], [[NaN]]], "params": {"weight": [[0.70703125]]}}, "model.layers.14.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.466796875]], [[78.0]]]}, "model.layers.14.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[29.875]]]}, "model.layers.14.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[55.5]]]}, "model.layers.14.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[27.375]]]}, "model.layers.14.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.14.self_attn.attn.impl.v_cache": {"inputs": [[[29.875]]]}, "model.layers.14.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[55.75]], [[78.0]], [[29.875]]], "outputs": [[[12.3125]], [[1.0]]]}, "model.layers.14.mlp.gate_up_proj": {"inputs": [[[29.125]]], "params": {"weight": [[0.28125]]}}, "model.layers.14.mlp.down_proj": {"inputs": [[[46.5]]], "outputs": [[[40.25]], [[4.220298886617108e+37]]], "params": {"weight": [[0.6015625]]}}, "model.layers.15.self_attn.qkv_proj": {"inputs": [[[214.0]]], "params": {"weight": [[0.193359375]]}}, "model.layers.15.self_attn.o_proj": {"inputs": [[[11.25]]], "outputs": [[[40.75]], [[3.4726081389880927e+37]]], "params": {"weight": [[0.486328125]]}}, "model.layers.15.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.41015625]], [[94.5]]]}, "model.layers.15.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[17.875]]]}, "model.layers.15.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[52.25]]]}, "model.layers.15.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[26.0]]]}, "model.layers.15.self_attn.attn.impl.k_cache": {"inputs": [[[94.5]]]}, "model.layers.15.self_attn.attn.impl.v_cache": {"inputs": [[[17.875]]]}, "model.layers.15.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[49.0]], [[86.5]], [[15.0625]]], "outputs": [[[11.0625]], [[1.0]]]}, "model.layers.15.mlp.gate_up_proj": {"inputs": [[[27.375]]], "params": {"weight": [[0.328125]]}}, "model.layers.15.mlp.down_proj": {"inputs": [[[47.75]]], "outputs": [[[51.5]], [[5.088450921364131e+36]]], "params": {"weight": [[0.640625]]}}, "model.layers.16.self_attn.qkv_proj": {"inputs": [[[190.0]]], "params": {"weight": [[0.228515625]]}}, "model.layers.16.self_attn.o_proj": {"inputs": [[[12.25]]], "outputs": [[[36.25]], [[1.26276659599567e+37]]], "params": {"weight": [[0.41015625]]}}, "model.layers.16.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.462890625]], [[90.5]]]}, "model.layers.16.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[16.375]]]}, "model.layers.16.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[56.25]]]}, "model.layers.16.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[24.0]]]}, "model.layers.16.self_attn.attn.impl.k_cache": {"inputs": [[[90.5]]]}, "model.layers.16.self_attn.attn.impl.v_cache": {"inputs": [[[16.375]]]}, "model.layers.16.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[58.0]], [[87.5]], [[16.375]]], "outputs": [[[12.25]], [[1.0]]]}, "model.layers.16.mlp.gate_up_proj": {"inputs": [[[30.375]]], "params": {"weight": [[0.30859375]]}}, "model.layers.16.mlp.down_proj": {"inputs": [[[44.0]]], "outputs": [[[37.25]], [[8.930750596679904e+36]]], "params": {"weight": [[0.6875]]}}, "model.layers.17.self_attn.qkv_proj": {"inputs": [[[192.0]]], "params": {"weight": [[0.1767578125]]}}, "model.layers.17.self_attn.o_proj": {"inputs": [[[12.375]]], "outputs": [[[39.75]], [[4.963835796759295e+36]]], "params": {"weight": [[0.37890625]]}}, "model.layers.17.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.4921875]], [[80.0]]]}, "model.layers.17.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[16.375]]]}, "model.layers.17.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[46.0]]]}, "model.layers.17.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.375]]]}, "model.layers.17.self_attn.attn.impl.k_cache": {"inputs": [[[80.0]]]}, "model.layers.17.self_attn.attn.impl.v_cache": {"inputs": [[[16.375]]]}, "model.layers.17.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[61.0]], [[80.0]], [[13.6875]]], "outputs": [[[12.375]], [[1.0]]]}, "model.layers.17.mlp.gate_up_proj": {"inputs": [[[31.75]]], "params": {"weight": [[0.298828125]]}}, "model.layers.17.mlp.down_proj": {"inputs": [[[59.25]]], "outputs": [[[26.75]], [[1.0567362566490081e+38]]], "params": {"weight": [[0.62890625]]}}, "model.layers.18.self_attn.qkv_proj": {"inputs": [[[153.0]]], "params": {"weight": [[0.189453125]]}}, "model.layers.18.self_attn.o_proj": {"inputs": [[[15.0625]]], "outputs": [[[22.375]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.2578125]]}}, "model.layers.18.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.51953125]], [[78.0]]]}, "model.layers.18.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[18.25]]]}, "model.layers.18.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[38.75]]]}, "model.layers.18.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.25]]]}, "model.layers.18.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.18.self_attn.attn.impl.v_cache": {"inputs": [[[18.25]]]}, "model.layers.18.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[63.75]], [[76.0]], [[18.25]]], "outputs": [[[15.0625]], [[1.0]]]}, "model.layers.18.mlp.gate_up_proj": {"inputs": [[[31.625]]], "params": {"weight": [[0.330078125]]}}, "model.layers.18.mlp.down_proj": {"inputs": [[[61.75]]], "outputs": [[[45.0]], [[1.26276659599567e+37]]], "params": {"weight": [[0.625]]}}, "model.layers.19.self_attn.qkv_proj": {"inputs": [[[154.0]]], "params": {"weight": [[0.1884765625]]}}, "model.layers.19.self_attn.o_proj": {"inputs": [[[14.875]]], "outputs": [[[39.25]], [[3.372916039304224e+37]]], "params": {"weight": [[0.40625]]}}, "model.layers.19.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.54296875]], [[87.0]]]}, "model.layers.19.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[23.625]]]}, "model.layers.19.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[56.25]]]}, "model.layers.19.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[24.0]]]}, "model.layers.19.self_attn.attn.impl.k_cache": {"inputs": [[[87.0]]]}, "model.layers.19.self_attn.attn.impl.v_cache": {"inputs": [[[23.625]]]}, "model.layers.19.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[62.75]], [[87.0]], [[23.625]]], "outputs": [[[14.25]], [[1.0]]]}, "model.layers.19.mlp.gate_up_proj": {"inputs": [[[37.0]]], "params": {"weight": [[0.52734375]]}}, "model.layers.19.mlp.down_proj": {"inputs": [[[376.0]]], "outputs": [[[107.5]], [[1.4756245268281733e+30]]], "params": {"weight": [[0.67578125]]}}, "model.layers.20.self_attn.qkv_proj": {"inputs": [[[0.78515625]]], "params": {"weight": [[0.07275390625]]}}, "model.layers.20.self_attn.o_proj": {"inputs": [[[0.138671875]]], "outputs": [[[0.419921875]], [[1.3823971156163125e+38]]], "params": {"weight": [[0.27734375]]}}, "model.layers.20.self_attn.attn.impl.matmul_qk": {"inputs": [[[7.112366251504909e-16]], [[1.1901590823981678e-13]]]}, "model.layers.20.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.3046875]]]}, "model.layers.20.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1280.0]]]}, "model.layers.20.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.20.self_attn.attn.impl.k_cache": {"inputs": [[[1.1901590823981678e-13]]]}, "model.layers.20.self_attn.attn.impl.v_cache": {"inputs": [[[0.3046875]]]}, "model.layers.20.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[1.0391687510491465e-13]], [[1.1901590823981678e-13]], [[0.287109375]]], "outputs": [[[0.138671875]], [[1.0]]]}, "model.layers.20.mlp.gate_up_proj": {"inputs": [[[35.25]]], "params": {"weight": [[0.388671875]]}}, "model.layers.20.mlp.down_proj": {"inputs": [[[76.5]]], "outputs": [[[39.0]], [[2.6086099417278974e+37]]], "params": {"weight": [[0.69140625]]}}, "model.layers.21.self_attn.qkv_proj": {"inputs": [[[158.0]]], "params": {"weight": [[0.166015625]]}}, "model.layers.21.self_attn.o_proj": {"inputs": [[[14.25]]], "outputs": [[[47.25]], [[1.6449196447838334e+37]]], "params": {"weight": [[0.4609375]]}}, "model.layers.21.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.59765625]], [[76.5]]]}, "model.layers.21.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[20.5]]]}, "model.layers.21.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[41.5]]]}, "model.layers.21.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.125]]]}, "model.layers.21.self_attn.attn.impl.k_cache": {"inputs": [[[76.5]]]}, "model.layers.21.self_attn.attn.impl.v_cache": {"inputs": [[[20.5]]]}, "model.layers.21.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[75.5]], [[73.5]], [[20.5]]], "outputs": [[[14.25]], [[1.0]]]}, "model.layers.21.mlp.gate_up_proj": {"inputs": [[[39.75]]], "params": {"weight": [[0.37890625]]}}, "model.layers.21.mlp.down_proj": {"inputs": [[[130.0]]], "outputs": [[[21.25]], [[1.3159357158270667e+38]]], "params": {"weight": [[0.56640625]]}}, "model.layers.22.self_attn.qkv_proj": {"inputs": [[[164.0]]], "params": {"weight": [[0.154296875]]}}, "model.layers.22.self_attn.o_proj": {"inputs": [[[11.875]]], "outputs": [[[18.625]], [[4.220298886617108e+37]]], "params": {"weight": [[0.28515625]]}}, "model.layers.22.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5625]], [[73.5]]]}, "model.layers.22.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[17.0]]]}, "model.layers.22.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[65.5]]]}, "model.layers.22.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[17.125]]]}, "model.layers.22.self_attn.attn.impl.k_cache": {"inputs": [[[73.5]]]}, "model.layers.22.self_attn.attn.impl.v_cache": {"inputs": [[[17.0]]]}, "model.layers.22.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[71.5]], [[72.0]], [[17.0]]], "outputs": [[[10.25]], [[1.0]]]}, "model.layers.22.mlp.gate_up_proj": {"inputs": [[[41.75]]], "params": {"weight": [[0.208984375]]}}, "model.layers.22.mlp.down_proj": {"inputs": [[[106.0]]], "outputs": [[[33.25]], [[1.26276659599567e+37]]], "params": {"weight": [[0.578125]]}}, "model.layers.23.self_attn.qkv_proj": {"inputs": [[[1.109375]]], "params": {"weight": [[0.04541015625]]}}, "model.layers.23.self_attn.o_proj": {"inputs": [[[0.06640625]]], "outputs": [[[0.130859375]], [[3.372916039304224e+37]]], "params": {"weight": [[0.11865234375]]}}, "model.layers.23.self_attn.attn.impl.matmul_qk": {"inputs": [[[6.002143226879753e-16]], [[9.992007221626409e-14]]]}, "model.layers.23.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.2158203125]]]}, "model.layers.23.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1280.0]]]}, "model.layers.23.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.23.self_attn.attn.impl.k_cache": {"inputs": [[[9.992007221626409e-14]]]}, "model.layers.23.self_attn.attn.impl.v_cache": {"inputs": [[[0.2158203125]]]}, "model.layers.23.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[7.72715225139109e-14]], [[9.992007221626409e-14]], [[0.173828125]]], "outputs": [[[0.06640625]], [[1.0]]]}, "model.layers.23.mlp.gate_up_proj": {"inputs": [[[43.75]]], "params": {"weight": [[0.3515625]]}}, "model.layers.23.mlp.down_proj": {"inputs": [[[145.0]]], "outputs": [[[13.0625]], [[3.4559927890407813e+37]]], "params": {"weight": [[0.484375]]}}, "model.layers.24.self_attn.qkv_proj": {"inputs": [[[1.0546875]]], "params": {"weight": [[0.044189453125]]}}, "model.layers.24.self_attn.o_proj": {"inputs": [[[0.0615234375]]], "outputs": [[[0.27734375]], [[8.930750596679904e+36]]], "params": {"weight": [[0.1181640625]]}}, "model.layers.24.self_attn.attn.impl.matmul_qk": {"inputs": [[[5.655198531684391e-16]], [[8.570921750106208e-14]]]}, "model.layers.24.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.197265625]]]}, "model.layers.24.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1280.0]]]}, "model.layers.24.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.24.self_attn.attn.impl.k_cache": {"inputs": [[[8.570921750106208e-14]]]}, "model.layers.24.self_attn.attn.impl.v_cache": {"inputs": [[[0.197265625]]]}, "model.layers.24.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[7.682743330406083e-14]], [[7.993605777301127e-14]], [[0.197265625]]], "outputs": [[[0.0615234375]], [[1.0]]]}, "model.layers.24.mlp.gate_up_proj": {"inputs": [[[43.25]]], "params": {"weight": [[0.2333984375]]}}, "model.layers.24.mlp.down_proj": {"inputs": [[[101.0]]], "outputs": [[[15.1875]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.48828125]]}}, "model.layers.25.self_attn.qkv_proj": {"inputs": [[[179.0]]], "params": {"weight": [[0.220703125]]}}, "model.layers.25.self_attn.o_proj": {"inputs": [[[11.0]]], "outputs": [[[8.3125]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.38671875]]}}, "model.layers.25.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.61328125]], [[78.0]]]}, "model.layers.25.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.875]]]}, "model.layers.25.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[30.5]]]}, "model.layers.25.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[16.125]]]}, "model.layers.25.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.25.self_attn.attn.impl.v_cache": {"inputs": [[[15.875]]]}, "model.layers.25.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[80.0]], [[72.0]], [[15.375]]], "outputs": [[[11.0]], [[1.0]]]}, "model.layers.25.mlp.gate_up_proj": {"inputs": [[[47.75]]], "params": {"weight": [[0.28515625]]}}, "model.layers.25.mlp.down_proj": {"inputs": [[[113.5]]], "outputs": [[[29.5]], [[3.4559927890407813e+37]]], "params": {"weight": [[0.61328125]]}}, "model.layers.26.self_attn.qkv_proj": {"inputs": [[[1.65625]]], "params": {"weight": [[0.058349609375]]}}, "model.layers.26.self_attn.o_proj": {"inputs": [[[0.08544921875]]], "outputs": [[[0.2001953125]], [[8.43229009826056e+36]]], "params": {"weight": [[0.166015625]]}}, "model.layers.26.self_attn.attn.impl.matmul_qk": {"inputs": [[[7.042977312465837e-16]], [[1.2434497875801753e-13]]]}, "model.layers.26.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.28515625]]]}, "model.layers.26.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1280.0]]]}, "model.layers.26.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.26.self_attn.attn.impl.k_cache": {"inputs": [[[1.2434497875801753e-13]]]}, "model.layers.26.self_attn.attn.impl.v_cache": {"inputs": [[[0.28515625]]]}, "model.layers.26.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[9.50350909079134e-14]], [[1.0746958878371515e-13]], [[0.28515625]]], "outputs": [[[0.08544921875]], [[1.0]]]}, "model.layers.26.mlp.gate_up_proj": {"inputs": [[[55.0]]], "params": {"weight": [[0.34765625]]}}, "model.layers.26.mlp.down_proj": {"inputs": [[[336.0]]], "outputs": [[[102.0]], [[3.43937743909347e+37]]], "params": {"weight": [[0.419921875]]}}, "model.layers.27.self_attn.qkv_proj": {"inputs": [[[1.8671875]]], "params": {"weight": [[0.06689453125]]}}, "model.layers.27.self_attn.o_proj": {"inputs": [[[0.126953125]]], "outputs": [[[0.44921875]], [[1.0467670466806212e+37]]], "params": {"weight": [[0.1640625]]}}, "model.layers.27.self_attn.attn.impl.matmul_qk": {"inputs": [[[8.534839501805891e-16]], [[1.412203687323199e-13]]]}, "model.layers.27.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.2890625]]]}, "model.layers.27.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1280.0]]]}, "model.layers.27.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.27.self_attn.attn.impl.k_cache": {"inputs": [[[1.412203687323199e-13]]]}, "model.layers.27.self_attn.attn.impl.v_cache": {"inputs": [[[0.2890625]]]}, "model.layers.27.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[1.1812772982011666e-13]], [[1.412203687323199e-13]], [[0.283203125]]], "outputs": [[[0.126953125]], [[1.0]]]}, "model.layers.27.mlp.gate_up_proj": {"inputs": [[[62.5]]], "params": {"weight": [[0.6640625]]}}, "model.layers.27.mlp.down_proj": {"inputs": [[[158.0]]], "outputs": [[[17.75]], [[4.220298886617108e+37]]], "params": {"weight": [[0.5546875]]}}, "model.layers.28.self_attn.qkv_proj": {"inputs": [[[171.0]]], "params": {"weight": [[0.228515625]]}}, "model.layers.28.self_attn.o_proj": {"inputs": [[[16.375]]], "outputs": [[[9.375]], [[4.220298886617108e+37]]], "params": {"weight": [[0.87109375]]}}, "model.layers.28.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.54296875]], [[76.0]]]}, "model.layers.28.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[25.25]]]}, "model.layers.28.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[17.375]]]}, "model.layers.28.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.0]]]}, "model.layers.28.self_attn.attn.impl.k_cache": {"inputs": [[[76.0]]]}, "model.layers.28.self_attn.attn.impl.v_cache": {"inputs": [[[25.25]]]}, "model.layers.28.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[67.5]], [[72.0]], [[25.25]]], "outputs": [[[14.9375]], [[1.0]]]}, "model.layers.28.mlp.gate_up_proj": {"inputs": [[[56.5]]], "params": {"weight": [[0.2451171875]]}}, "model.layers.28.mlp.down_proj": {"inputs": [[[138.0]]], "outputs": [[[29.0]], [[3.4559927890407813e+37]]], "params": {"weight": [[0.5859375]]}}, "model.layers.29.self_attn.qkv_proj": {"inputs": [[[5.53125]]], "params": {"weight": [[0.10546875]]}}, "model.layers.29.self_attn.o_proj": {"inputs": [[[0.46875]]], "outputs": [[[2.46875]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.2197265625]]}}, "model.layers.29.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.5118795932144167e-15]], [[4.760636329592671e-13]]]}, "model.layers.29.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.6171875]]]}, "model.layers.29.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1280.0]]]}, "model.layers.29.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.29.self_attn.attn.impl.k_cache": {"inputs": [[[4.760636329592671e-13]]]}, "model.layers.29.self_attn.attn.impl.v_cache": {"inputs": [[[0.6171875]]]}, "model.layers.29.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[3.197442310920451e-13]], [[4.760636329592671e-13]], [[0.58984375]]], "outputs": [[[0.46875]], [[1.0]]]}, "model.layers.29.mlp.gate_up_proj": {"inputs": [[[59.25]]], "params": {"weight": [[0.326171875]]}}, "model.layers.29.mlp.down_proj": {"inputs": [[[136.0]]], "outputs": [[[40.25]], [[1.1796898462591128e+37]]], "params": {"weight": [[0.57421875]]}}, "model.layers.30.self_attn.qkv_proj": {"inputs": [[[180.0]]], "params": {"weight": [[0.193359375]]}}, "model.layers.30.self_attn.o_proj": {"inputs": [[[26.5]]], "outputs": [[[20.25]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.77734375]]}}, "model.layers.30.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.55859375]], [[77.5]]]}, "model.layers.30.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[38.5]]]}, "model.layers.30.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[34.0]]]}, "model.layers.30.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[35.5]]]}, "model.layers.30.self_attn.attn.impl.k_cache": {"inputs": [[[77.5]]]}, "model.layers.30.self_attn.attn.impl.v_cache": {"inputs": [[[38.5]]]}, "model.layers.30.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[68.5]], [[74.5]], [[37.75]]], "outputs": [[[21.25]], [[1.0]]]}, "model.layers.30.mlp.gate_up_proj": {"inputs": [[[62.0]]], "params": {"weight": [[0.33984375]]}}, "model.layers.30.mlp.down_proj": {"inputs": [[[139.0]]], "outputs": [[[37.75]], [[3.4726081389880927e+37]]], "params": {"weight": [[0.55078125]]}}, "model.layers.31.self_attn.qkv_proj": {"inputs": [[[168.0]]], "params": {"weight": [[0.265625]]}}, "model.layers.31.self_attn.o_proj": {"inputs": [[[19.875]]], "outputs": [[[42.0]], [[1.2544589210220144e+37]]], "params": {"weight": [[0.326171875]]}}, "model.layers.31.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.62109375]], [[76.0]]]}, "model.layers.31.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[24.625]]]}, "model.layers.31.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[51.25]]]}, "model.layers.31.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[25.375]]]}, "model.layers.31.self_attn.attn.impl.k_cache": {"inputs": [[[76.0]]]}, "model.layers.31.self_attn.attn.impl.v_cache": {"inputs": [[[24.625]]]}, "model.layers.31.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[74.5]], [[73.0]], [[22.625]]], "outputs": [[[18.625]], [[1.0]]]}, "model.layers.31.mlp.gate_up_proj": {"inputs": [[[63.75]]], "params": {"weight": [[0.302734375]]}}, "model.layers.31.mlp.down_proj": {"inputs": [[[178.0]]], "outputs": [[[35.25]], [[3.4559927890407813e+37]]], "params": {"weight": [[0.451171875]]}}, "model.layers.32.self_attn.qkv_proj": {"inputs": [[[175.0]]], "params": {"weight": [[0.259765625]]}}, "model.layers.32.self_attn.o_proj": {"inputs": [[[26.25]]], "outputs": [[[57.0]], [[3.4726081389880927e+37]]], "params": {"weight": [[0.75390625]]}}, "model.layers.32.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.75]], [[82.5]]]}, "model.layers.32.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[30.75]]]}, "model.layers.32.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[49.5]]]}, "model.layers.32.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[25.375]]]}, "model.layers.32.self_attn.attn.impl.k_cache": {"inputs": [[[82.5]]]}, "model.layers.32.self_attn.attn.impl.v_cache": {"inputs": [[[30.75]]]}, "model.layers.32.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[96.0]], [[77.5]], [[30.25]]], "outputs": [[[23.25]], [[1.0]]]}, "model.layers.32.mlp.gate_up_proj": {"inputs": [[[68.5]]], "params": {"weight": [[0.43359375]]}}, "model.layers.32.mlp.down_proj": {"inputs": [[[205.0]]], "outputs": [[[49.25]], [[1.0567362566490081e+38]]], "params": {"weight": [[0.4921875]]}}, "model.layers.33.self_attn.qkv_proj": {"inputs": [[[205.0]]], "params": {"weight": [[0.20703125]]}}, "model.layers.33.self_attn.o_proj": {"inputs": [[[31.125]]], "outputs": [[[42.5]], [[3.4726081389880927e+37]]], "params": {"weight": [[0.47265625]]}}, "model.layers.33.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.640625]], [[92.5]]]}, "model.layers.33.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[34.0]]]}, "model.layers.33.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[38.75]]]}, "model.layers.33.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[31.25]]]}, "model.layers.33.self_attn.attn.impl.k_cache": {"inputs": [[[92.5]]]}, "model.layers.33.self_attn.attn.impl.v_cache": {"inputs": [[[34.0]]]}, "model.layers.33.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[77.5]], [[90.5]], [[29.375]]], "outputs": [[[27.5]], [[1.0]]]}, "model.layers.33.mlp.gate_up_proj": {"inputs": [[[70.5]]], "params": {"weight": [[0.384765625]]}}, "model.layers.33.mlp.down_proj": {"inputs": [[[244.0]]], "outputs": [[[91.5]], [[8.681520347470232e+36]]], "params": {"weight": [[0.5234375]]}}, "model.layers.34.self_attn.qkv_proj": {"inputs": [[[186.0]]], "params": {"weight": [[0.310546875]]}}, "model.layers.34.self_attn.o_proj": {"inputs": [[[36.0]]], "outputs": [[[99.5]], [[1.5535352200736204e+37]]], "params": {"weight": [[0.353515625]]}}, "model.layers.34.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.625]], [[85.5]]]}, "model.layers.34.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[39.75]]]}, "model.layers.34.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[39.25]]]}, "model.layers.34.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[33.0]]]}, "model.layers.34.self_attn.attn.impl.k_cache": {"inputs": [[[85.5]]]}, "model.layers.34.self_attn.attn.impl.v_cache": {"inputs": [[[39.75]]]}, "model.layers.34.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[81.5]], [[80.5]], [[39.75]]], "outputs": [[[36.0]], [[1.0]]]}, "model.layers.34.mlp.gate_up_proj": {"inputs": [[[82.5]]], "params": {"weight": [[0.294921875]]}}, "model.layers.34.mlp.down_proj": {"inputs": [[[290.0]]], "outputs": [[[88.0]], [[7.643060975763266e+36]]], "params": {"weight": [[0.4921875]]}}, "model.layers.35.self_attn.qkv_proj": {"inputs": [[[197.0]]], "params": {"weight": [[0.25]]}}, "model.layers.35.self_attn.o_proj": {"inputs": [[[28.75]]], "outputs": [[[75.5]], [[4.220298886617108e+37]]], "params": {"weight": [[0.451171875]]}}, "model.layers.35.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.57421875]], [[88.5]]]}, "model.layers.35.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[33.0]]]}, "model.layers.35.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[66.0]]]}, "model.layers.35.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[28.75]]]}, "model.layers.35.self_attn.attn.impl.k_cache": {"inputs": [[[88.5]]]}, "model.layers.35.self_attn.attn.impl.v_cache": {"inputs": [[[33.0]]]}, "model.layers.35.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[75.0]], [[85.5]], [[31.0]]], "outputs": [[[28.75]], [[1.0]]]}, "model.layers.35.mlp.gate_up_proj": {"inputs": [[[105.0]]], "params": {"weight": [[0.3671875]]}}, "model.layers.35.mlp.down_proj": {"inputs": [[[536.0]]], "outputs": [[[108.5]], [[1.0799977465752441e+37]]], "params": {"weight": [[0.5078125]]}}, "model.layers.36.self_attn.qkv_proj": {"inputs": [[[202.0]]], "params": {"weight": [[0.2353515625]]}}, "model.layers.36.self_attn.o_proj": {"inputs": [[[38.5]]], "outputs": [[[79.5]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.43359375]]}}, "model.layers.36.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.63671875]], [[90.0]]]}, "model.layers.36.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[48.25]]]}, "model.layers.36.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[58.0]]]}, "model.layers.36.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[42.5]]]}, "model.layers.36.self_attn.attn.impl.k_cache": {"inputs": [[[90.0]]]}, "model.layers.36.self_attn.attn.impl.v_cache": {"inputs": [[[48.25]]]}, "model.layers.36.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[79.0]], [[90.0]], [[42.5]]], "outputs": [[[35.5]], [[1.0]]]}, "model.layers.36.mlp.gate_up_proj": {"inputs": [[[112.0]]], "params": {"weight": [[0.392578125]]}}, "model.layers.36.mlp.down_proj": {"inputs": [[[604.0]]], "outputs": [[[96.5]], [[2.857840190937569e+37]]], "params": {"weight": [[0.4921875]]}}, "model.layers.37.self_attn.qkv_proj": {"inputs": [[[217.0]]], "params": {"weight": [[0.234375]]}}, "model.layers.37.self_attn.o_proj": {"inputs": [[[48.75]]], "outputs": [[[88.0]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.41015625]]}}, "model.layers.37.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.8046875]], [[99.5]]]}, "model.layers.37.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[54.75]]]}, "model.layers.37.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[35.0]]]}, "model.layers.37.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[49.0]]]}, "model.layers.37.self_attn.attn.impl.k_cache": {"inputs": [[[99.5]]]}, "model.layers.37.self_attn.attn.impl.v_cache": {"inputs": [[[54.75]]]}, "model.layers.37.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[103.0]], [[97.0]], [[53.5]]], "outputs": [[[46.75]], [[1.0]]]}, "model.layers.37.mlp.gate_up_proj": {"inputs": [[[142.0]]], "params": {"weight": [[0.25390625]]}}, "model.layers.37.mlp.down_proj": {"inputs": [[[1400.0]]], "outputs": [[[780.0]], [[1.2544589210220144e+37]]], "params": {"weight": [[0.54296875]]}}, "model.layers.38.self_attn.qkv_proj": {"inputs": [[[166.0]]], "params": {"weight": [[0.2001953125]]}}, "model.layers.38.self_attn.o_proj": {"inputs": [[[45.75]]], "outputs": [[[201.0]], [[1.0218440217596541e+37]]], "params": {"weight": [[0.408203125]]}}, "model.layers.38.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.6328125]], [[90.5]]]}, "model.layers.38.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[71.5]]]}, "model.layers.38.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[85.0]]]}, "model.layers.38.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[57.25]]]}, "model.layers.38.self_attn.attn.impl.k_cache": {"inputs": [[[90.5]]]}, "model.layers.38.self_attn.attn.impl.v_cache": {"inputs": [[[71.5]]]}, "model.layers.38.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[83.5]], [[83.5]], [[70.5]]], "outputs": [[[45.75]], [[1.0]]]}, "model.layers.38.mlp.gate_up_proj": {"inputs": [[[179.0]]], "params": {"weight": [[0.34765625]]}}, "model.layers.38.mlp.down_proj": {"inputs": [[[1192.0]]], "outputs": [[[636.0]], [[1.8110731442569479e+37]]], "params": {"weight": [[0.41796875]]}}, "model.layers.39.self_attn.qkv_proj": {"inputs": [[[270.0]]], "params": {"weight": [[0.1904296875]]}}, "model.layers.39.self_attn.o_proj": {"inputs": [[[70.0]]], "outputs": [[[390.0]], [[1.2544589210220144e+37]]], "params": {"weight": [[0.48046875]]}}, "model.layers.39.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.83203125]], [[101.5]]]}, "model.layers.39.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[73.5]]]}, "model.layers.39.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[40.0]]]}, "model.layers.39.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[70.0]]]}, "model.layers.39.self_attn.attn.impl.k_cache": {"inputs": [[[101.5]]]}, "model.layers.39.self_attn.attn.impl.v_cache": {"inputs": [[[73.5]]]}, "model.layers.39.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[123.5]], [[101.5]], [[69.5]]], "outputs": [[[63.5]], [[1.0]]]}, "model.layers.39.mlp.gate_up_proj": {"inputs": [[[474.0]]], "params": {"weight": [[0.55078125]]}}, "model.layers.39.mlp.down_proj": {"inputs": [[[10176.0]]], "outputs": [[[13696.0]], [[1.26276659599567e+37]]], "params": {"weight": [[0.58984375]]}}, "lm_head": {"inputs": [[[1360.0]]], "params": {"weight": [[0.337890625]]}}}}