{
    "GlobalRank": null,
    "LocalRank": 0,
    "Mode": "Scale",
    "Nodes": {
        "transformer.h.0.attn.c_attn": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.000244140625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.0.attn.c_proj": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.5
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.0.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.00390625,
                0.25
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.015625
            ],
            "outputs": [
                0.000244140625
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                4.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.v_cache": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.0.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.0625,
                0.25,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.0.mlp.c_fc": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.0.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                32.0
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.1.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.1.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.5
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.1.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.0078125,
                0.125
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.1.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.1.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.1.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                2.0
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.2.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.2.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.2.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.k_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.2.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.0625,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.2.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.2.mlp.c_proj": {
            "inputs": [
                0.5
            ],
            "outputs": [
                4.0
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.3.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.3.attn.c_proj": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.3.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.03125,
                0.0625
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.k_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.3.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.3.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.3.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                4.0
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.4.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.4.attn.c_proj": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.4.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.015625
            ],
            "outputs": [
                0.000244140625
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.v_cache": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.4.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.015625,
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.4.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.4.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                2.0
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.5.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.5.attn.c_proj": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.5.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.015625
            ],
            "outputs": [
                0.000244140625
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.v_cache": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.5.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.015625,
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.5.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.5.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.5
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.6.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.6.attn.c_proj": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.6.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.6.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.6.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.6.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.7.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.7.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.7.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.7.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.7.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.7.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.8.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.8.attn.c_proj": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.8.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.015625
            ],
            "outputs": [
                0.000244140625
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.v_cache": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.8.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.015625,
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.8.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.8.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.9.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.9.attn.c_proj": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.9.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.03125,
                0.125
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.015625
            ],
            "outputs": [
                0.000244140625
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.v_cache": {
            "inputs": [
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.9.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.015625,
                0.015625
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.9.mlp.c_fc": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.9.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.10.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.10.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.10.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.10.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.10.mlp.c_fc": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.10.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.11.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.11.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.11.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.11.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.11.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.11.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.12.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.12.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.12.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.12.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.12.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.12.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.13.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.13.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.13.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.13.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.13.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.13.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.5
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.14.attn.c_attn": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.14.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.14.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.03125,
                0.125
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.14.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.25,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.14.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.14.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.15.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.15.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.15.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.15.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.15.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0078125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.15.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.5
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.16.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.16.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.16.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.16.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.16.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.16.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.5
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.17.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.17.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.17.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                4.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.17.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.17.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0078125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.17.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.18.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.18.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.18.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.18.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.18.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.18.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.19.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.19.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.19.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.19.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.19.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.19.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.20.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.20.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.20.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.20.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.25,
                0.125,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.20.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.20.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.21.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.21.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.21.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.21.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.21.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.21.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.22.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.22.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.22.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.22.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.22.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.22.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.23.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.23.attn.c_proj": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.23.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.03125
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.v_cache": {
            "inputs": [
                0.03125
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.23.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.03125,
                0.015625
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.23.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.23.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.24.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.24.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.24.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.24.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.24.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.24.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.25.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.25.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.25.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                4.0
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.25.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.25.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.25.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.26.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.26.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.26.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.26.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.26.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.26.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.27.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.27.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.27.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.27.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.27.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.27.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.28.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.28.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.28.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.28.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.28.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.28.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.29.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.29.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.29.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.29.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.29.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.29.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.30.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.30.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.30.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.30.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.30.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.30.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.31.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.31.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.31.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.31.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.31.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.31.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.32.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.000244140625
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.32.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.32.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.32.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.32.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.32.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.33.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.33.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.33.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.33.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.33.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.33.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.34.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.34.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.34.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.34.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.34.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.34.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.35.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.000244140625
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.35.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.03125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.35.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.35.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.35.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.35.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.36.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.000244140625
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.36.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.36.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.36.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.36.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.36.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.37.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.37.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.37.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.0625
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.v_cache": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.37.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.0625,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.37.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.0078125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.37.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.38.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.38.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.38.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.38.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.38.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.38.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.39.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.39.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.39.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.39.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.39.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.39.mlp.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.40.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.40.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.40.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.40.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.40.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.40.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.41.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.41.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.41.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.41.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.41.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.41.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.42.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.42.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.42.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.42.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.42.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.42.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.43.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.43.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.03125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.43.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.43.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.43.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.43.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.44.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.44.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.0625
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.44.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.44.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.44.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.44.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.45.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.45.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.45.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.45.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.45.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.45.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.46.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.46.attn.c_proj": {
            "inputs": [
                0.0625
            ],
            "outputs": [
                0.125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.46.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.46.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.0625
            ],
            "params": {}
        },
        "transformer.h.46.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.46.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.5
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.47.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.47.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.47.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.47.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.47.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.47.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.5
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.48.attn.c_attn": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.48.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.25
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.48.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.48.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.48.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.48.mlp.c_proj": {
            "inputs": [
                0.5
            ],
            "outputs": [
                2.0
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.49.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.49.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                1.0
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.49.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.49.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.25,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.49.mlp.c_fc": {
            "inputs": [
                1.0
            ],
            "outputs": [
                0.00390625
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.49.mlp.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                2.0
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.50.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0009765625
            ],
            "params": {
                "weight": 0.001953125
            }
        },
        "transformer.h.50.attn.c_proj": {
            "inputs": [
                0.125
            ],
            "outputs": [
                4.0
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.50.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.125
            ],
            "outputs": [
                0.001953125
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                1.0
            ],
            "outputs": [
                0.015625
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.k_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.v_cache": {
            "inputs": [
                0.125
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.50.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.125,
                0.125,
                0.125,
                0.015625
            ],
            "outputs": [
                0.125
            ],
            "params": {}
        },
        "transformer.h.50.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.001953125
            ],
            "params": {
                "weight": 0.00390625
            }
        },
        "transformer.h.50.mlp.c_proj": {
            "inputs": [
                0.5
            ],
            "outputs": [
                4.0
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.51.attn.c_attn": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.00048828125
            ],
            "params": {
                "weight": 0.0009765625
            }
        },
        "transformer.h.51.attn.c_proj": {
            "inputs": [
                0.25
            ],
            "outputs": [
                4.0
            ],
            "params": {
                "weight": 0.0078125
            }
        },
        "transformer.h.51.attn.attn.impl.matmul_qk": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.matmul_av": {
            "inputs": [
                0.015625,
                0.25
            ],
            "outputs": [
                0.00390625
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.batch2block_matmul": {
            "inputs": [
                0.015625,
                2.0
            ],
            "outputs": [
                0.03125
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.block2batch_matmul": {
            "inputs": [
                0.015625,
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.k_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.v_cache": {
            "inputs": [
                0.25
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.51.attn.attn.impl.fused_scaled_dot_product_attention": {
            "inputs": [
                0.5,
                0.25,
                0.25,
                0.015625
            ],
            "outputs": [
                0.25
            ],
            "params": {}
        },
        "transformer.h.51.mlp.c_fc": {
            "inputs": [
                0.5
            ],
            "outputs": [
                0.0078125
            ],
            "params": {
                "weight": 0.015625
            }
        },
        "transformer.h.51.mlp.c_proj": {
            "inputs": [
                1.0
            ],
            "outputs": [
                4.0
            ],
            "params": {
                "weight": 0.03125
            }
        }
    }
}